"""
DMMR Pre-training Lightning Module.

Implements pre-training phase with reconstruction loss and domain adversarial training.
"""
from typing import Tuple, Dict, Any, Optional

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchmetrics

from .lightning_base import DMMRBaseLightningModule
from ..models.pretraining_model import DMMRPreTrainingModel


class DMMRPreTrainingModule(DMMRBaseLightningModule):
    """
    DMMR Pre-training Lightning Module.
    
    DMMR ì‚¬ì „í›ˆë ¨ Lightning ëª¨ë“ˆë¡œ ë‹¤ìŒ ê¸°ëŠ¥ë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤:
    - ë‹¤ì¤‘ ë””ì½”ë”ë¥¼ ì´ìš©í•œ ì¬êµ¬ì„± ì†ì‹¤
    - ê·¸ë˜ë””ì–¸íŠ¸ ì—­ì „ì„ í†µí•œ ë„ë©”ì¸ ì ëŒ€ì  í›ˆë ¨
    - ë…¸ì´ì¦ˆ ì£¼ì… ë° í˜¼í•© ì¦ê°•
    - ë‹¤ì¤‘ ì†ŒìŠ¤ ë„ë©”ì¸ ì²˜ë¦¬
    
    Args:
        number_of_source: ì†ŒìŠ¤ ë„ë©”ì¸ ìˆ˜ (default: 14)
        noise_injection_type: ë…¸ì´ì¦ˆ ì£¼ì… íƒ€ì… ("shuffle", "mask", "none")
        noise_rate: ë…¸ì´ì¦ˆ ë¹„ìœ¨ (default: 0.2)
    """
    
    def __init__(
        self,
        number_of_source: int = 14,
        noise_injection_type: str = "shuffle",
        noise_rate: float = 0.2,
        **kwargs
    ):
        # DMMR ê¸°ë³¸ê°’ ì„¤ì •
        dmmr_defaults = {
            'num_classes': 3,
            'input_dim': 310,
            'hidden_dim': 64,
            'batch_size': 10,
            'time_steps': 15,
            'beta': 1.0,
        }
        
        # ì‚¬ì „í›ˆë ¨ íŠ¹í™” íŒŒë¼ë¯¸í„°ë¥¼ ë¨¼ì € ì„¤ì •
        self.number_of_source = number_of_source
        self.noise_injection_type = noise_injection_type
        self.noise_rate = noise_rate
        
        config = {**dmmr_defaults, **kwargs}
        super().__init__(**config)
        
        # ğŸ”§ í•µì‹¬ ë³€ê²½: DMMRì€ í•­ìƒ Manual optimization
        self.automatic_optimization = False
        self.subject_iterators = {}
        
        # ì‚¬ì „í›ˆë ¨ íŠ¹í™” ë©”íŠ¸ë¦­ ì„¤ì •
        self._setup_pretraining_metrics()
    
    def _build_model(self) -> None:
        """DMMR ì‚¬ì „í›ˆë ¨ ëª¨ë¸ êµ¬ì¡° ìƒì„±."""
        self.model = DMMRPreTrainingModel(
            number_of_source=self.number_of_source,
            number_of_category=self.num_classes,
            batch_size=self.batch_size,
            time_steps=self.time_steps,
            input_dim=self.input_dim
        )
    
    def _setup_pretraining_metrics(self) -> None:
        """ì‚¬ì „í›ˆë ¨ íŠ¹í™” ë©”íŠ¸ë¦­ ì„¤ì •."""
        # ì†ì‹¤ ë©”íŠ¸ë¦­
        self.train_loss_metrics = torchmetrics.MetricCollection({
            "total_loss": torchmetrics.MeanMetric(),
            "rec_loss": torchmetrics.MeanMetric(),
            "sim_loss": torchmetrics.MeanMetric(),
        }, prefix="train_")
        
        self.val_loss_metrics = self.train_loss_metrics.clone(prefix="val_")
        
        # ë„ë©”ì¸ ì ëŒ€ì  ì •í™•ë„
        self.domain_accuracy = torchmetrics.Accuracy(
            task='multiclass', 
            num_classes=self.number_of_source
        )
    
    def forward(
        self, 
        x: torch.Tensor, 
        corres: torch.Tensor, 
        subject_id: torch.Tensor, 
        m: float = 0.0,
        subject_mask: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass for pre-training.
        
        Args:
            x: Input EEG data
            corres: Correspondence data for reconstruction
            subject_id: Subject/domain IDs
            m: Gradient reversal strength
            
        Returns:
            Tuple of (reconstruction_loss, similarity_loss)
        """
        return self.model.forward(x, corres, subject_id, m, mark=0, subject_mask=subject_mask)
    
    def training_step(self, batch, batch_idx):
        """DMMR ì›ë³¸ ë°©ì‹: 4D ë°ì´í„°ì—ì„œ subject_num ì¶• ê¸°ì¤€ í”¼í—˜ìë³„ ìˆœí™˜ í›ˆë ¨ (Manual Optimization)"""
        
        # ğŸ”§ í•µì‹¬ ë³€ê²½: Manual optimization
        optimizer = self.optimizers()
        
        # DataModule ì¶œë ¥: (source_data, correspondence_data, subject_ids, source_labels, subject_mask_data)
        source_data, correspondence_data, subject_ids, source_labels, subject_mask_data = batch
        batch_size, subject_num, time_steps, features = source_data.shape
        
        total_loss = 0.0
        total_rec_loss = 0.0
        total_sim_loss = 0.0
        num_processed = 0
        
        # GRL ê°•ë„ ê³„ì‚° (ì›ë³¸ DMMRê³¼ ë™ì¼)
        grl_strength = self._calculate_grl_strength()
        
        print(f"ğŸ” Training batch shapes: source_data={source_data.shape}, correspondence_data={correspondence_data.shape}")
        print(f"ğŸ” Subject count: {subject_num}, batch_size: {batch_size}")
        
        # ğŸ¯ í•µì‹¬: subject_num ì¶• ê¸°ì¤€ìœ¼ë¡œ í”¼í—˜ìë³„ ìˆœí™˜ ì²˜ë¦¬ (ì›ë³¸ DMMR ë°©ì‹)
        for subject_idx in range(subject_num):
            try:
                # í˜„ì¬ í”¼í—˜ìì˜ ë°ì´í„° ì¶”ì¶œ (ì¶• ê¸°ì¤€ ìŠ¬ë¼ì´ì‹±)
                subject_batch_data = source_data[:, subject_idx, :, :]  # (batch_size, time_steps, features)
                subject_correspondence = correspondence_data[subject_idx,:, :, :]  # (batch_size*subject_nums,time_steps, features)
                subject_labels = source_labels[:, subject_idx]  # (batch_size,)
                subject_mask = subject_mask_data[subject_idx, :, :]  # (batch_size, subject_num)
                
                # í”¼í—˜ì ID í…ì„œ ìƒì„± (ì›ë³¸ DMMR ë°©ì‹: ëª¨ë“  ë°°ì¹˜ì—ì„œ ë™ì¼í•œ subject_idx)
                current_subject_ids = torch.full(
                    (batch_size,), 
                    subject_idx, 
                    dtype=torch.long, 
                    device=source_data.device
                )
                
                # DMMR forward (ì›ë³¸ê³¼ ë™ì¼í•œ í˜¸ì¶œ ë°©ì‹)
                rec_loss, sim_loss = self.forward(
                    subject_batch_data, subject_correspondence, 
                    current_subject_ids, m=grl_strength, subject_mask=subject_mask
                )
                
                # Loss ê³„ì‚° (ì›ë³¸ DMMRê³¼ ë™ì¼)
                subject_loss = rec_loss + self.beta * sim_loss
                
                # ğŸ”§ í•µì‹¬: Manual backward (ì›ë³¸ DMMR ë°©ì‹ - í”¼í—˜ìë³„ ë…ë¦½ì  backward)
                self.manual_backward(subject_loss)
                
                # Loss ëˆ„ì 
                total_loss += subject_loss.detach()
                total_rec_loss += rec_loss.detach()
                total_sim_loss += sim_loss.detach()
                num_processed += 1
                
                # Debug info (ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ì²« ë²ˆì§¸ í”¼í—˜ìì—ì„œë§Œ)
                if batch_idx == 0 and subject_idx == 0:
                    print(f"ğŸ”„ Subject {subject_idx}: rec_loss={rec_loss:.4f}, sim_loss={sim_loss:.4f}")
                    print(f"ğŸ” Subject shapes: data={subject_batch_data.shape}, correspondence={subject_correspondence.shape}, labels={subject_labels.shape}")
                
            except Exception as e:
                print(f"âš ï¸ Subject {subject_idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # Optimizer step (ëª¨ë“  í”¼í—˜ì ì²˜ë¦¬ í›„ - ì›ë³¸ DMMR ë°©ì‹)
        if num_processed > 0:
            optimizer.step()
            optimizer.zero_grad()
            
            avg_total_loss = total_loss / num_processed
            avg_rec_loss = total_rec_loss / num_processed
            avg_sim_loss = total_sim_loss / num_processed
        else:
            avg_total_loss = torch.tensor(0.0, device=self.device)
            avg_rec_loss = torch.tensor(0.0, device=self.device)
            avg_sim_loss = torch.tensor(0.0, device=self.device)
        
        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self.train_loss_metrics['total_loss'].update(
            avg_total_loss.item() if isinstance(avg_total_loss, torch.Tensor) else avg_total_loss
        )
        self.train_loss_metrics['rec_loss'].update(
            avg_rec_loss.item() if isinstance(avg_rec_loss, torch.Tensor) else avg_rec_loss
        )
        self.train_loss_metrics['sim_loss'].update(
            avg_sim_loss.item() if isinstance(avg_sim_loss, torch.Tensor) else avg_sim_loss
        )
        
        # ë¡œê¹…
        self.log_dict({
            'train_total_loss': avg_total_loss,
            'train_rec_loss': avg_rec_loss,
            'train_sim_loss': avg_sim_loss,
            'grl_strength': grl_strength,
            'subjects_processed': num_processed,
            'subject_num': subject_num,
            'batch_size': batch_size
        }, on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)
        
        return avg_total_loss
    
    def _get_subject_batch(self, subject_id: str, subject_dataloader):
        """Subjectë³„ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸° (ì›ë³¸ DMMR ë°©ì‹)"""
        
        # Iterator ê´€ë¦¬ (ì›ë³¸ DMMRê³¼ ë™ì¼)
        if subject_id not in self.subject_iterators:
            self.subject_iterators[subject_id] = iter(subject_dataloader)
        
        try:
            # Subjectì—ì„œ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
            batch = next(self.subject_iterators[subject_id])
            return batch
        except StopIteration:
            # Iterator ì¬ì‹œì‘ (ì›ë³¸ DMMRê³¼ ë™ì¼)
            self.subject_iterators[subject_id] = iter(subject_dataloader)
            try:
                batch = next(self.subject_iterators[subject_id])
                return batch
            except StopIteration:
                return None
    
    def _calculate_grl_strength(self) -> float:
        """GRL ê°•ë„ ê³„ì‚° (ì›ë³¸ DMMRê³¼ ë™ì¼)"""
        if hasattr(self.trainer, 'estimated_stepping_batches') and self.trainer.estimated_stepping_batches > 0:
            progress = self.trainer.global_step / max(1, self.trainer.estimated_stepping_batches)
        else:
            progress = min(1.0, self.current_epoch / 100.0)
        
        # ì›ë³¸ DMMR ê³µì‹: 2.0 / (1.0 + exp(-10 * progress)) - 1.0
        m = 2.0 / (1.0 + torch.exp(torch.tensor(-10.0 * progress))) - 1.0
        return float(m)
    
    def validation_step(self, batch, batch_idx):
        """DMMR ì›ë³¸ ë°©ì‹: 4D ë°ì´í„°ì—ì„œ subject_num ì¶• ê¸°ì¤€ í”¼í—˜ìë³„ ìˆœí™˜ Validation"""

        # DataModule ì¶œë ¥: (source_data, correspondence_data, subject_ids, source_labels, subject_mask_data)
        source_data, correspondence_data, _, source_labels, subject_mask_data = batch
        batch_size, subject_num, _, _ = source_data.shape
        
        total_loss = 0.0
        total_rec_loss = 0.0
        total_sim_loss = 0.0
        num_processed = 0

        # ğŸ¯ í•µì‹¬: subject_num ì¶• ê¸°ì¤€ìœ¼ë¡œ í”¼í—˜ìë³„ ìˆœí™˜ ì²˜ë¦¬ (training_stepê³¼ ë™ì¼)
        for subject_idx in range(subject_num):
            try:
                # í˜„ì¬ í”¼í—˜ìì˜ ë°ì´í„° ì¶”ì¶œ (ì¶• ê¸°ì¤€ ìŠ¬ë¼ì´ì‹±)
                subject_batch_data = source_data[:, subject_idx, :, :]  # (batch_size, time_steps, features)
                subject_correspondence = correspondence_data[subject_idx,:, :, :]  # (batch_size, subject_nums*time_steps, features)
                subject_mask = subject_mask_data[subject_idx, :, :]  # (batch_size, subject_num)

                # print(f"ğŸ” Validation batch shapes: source_data={subject_batch_data.shape}, correspondence_data={subject_correspondence.shape}")
                
                # í”¼í—˜ì ID í…ì„œ ìƒì„±
                current_subject_ids = torch.full(
                    (batch_size,), 
                    subject_idx, 
                    dtype=torch.long, 
                    device=source_data.device
                )
                # print(f"ğŸ” Current subject IDs: {current_subject_ids}")
                
                # Forward pass (validationì—ì„œëŠ” GRL ì—†ìŒ: m=0.0)
                rec_loss, sim_loss = self.forward(
                    subject_batch_data, subject_correspondence, 
                    current_subject_ids, m=0.0, subject_mask=subject_mask
                )
                
                # Loss ê³„ì‚°
                subject_loss = rec_loss + self.beta * sim_loss
                
                # Loss ëˆ„ì 
                total_loss += subject_loss.detach()
                total_rec_loss += rec_loss.detach()
                total_sim_loss += sim_loss.detach()
                num_processed += 1
                
                # Debug info (ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ì²« ë²ˆì§¸ í”¼í—˜ìì—ì„œë§Œ)
                if batch_idx == 0 and subject_idx == 0:
                    print(f"ğŸ” Val Subject {subject_idx}: rec_loss={rec_loss:.4f}, sim_loss={sim_loss:.4f}")
                    print(f"ğŸ” Val Subject shapes: data={subject_batch_data.shape}, correspondence={subject_correspondence.shape}")
                
            except Exception as e:
                import traceback
                traceback.print_exc()
                raise RuntimeError(f"âš ï¸ Subject {subject_idx} validation failed: {e}") 
        
        # í‰ê·  ê³„ì‚°
        if num_processed > 0:
            avg_total_loss = total_loss / num_processed
            avg_rec_loss = total_rec_loss / num_processed
            avg_sim_loss = total_sim_loss / num_processed
        else:
            avg_total_loss = torch.tensor(0.0, device=self.device)
            avg_rec_loss = torch.tensor(0.0, device=self.device)
            avg_sim_loss = torch.tensor(0.0, device=self.device)
        
        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self.val_loss_metrics['total_loss'].update(
            avg_total_loss.item() if isinstance(avg_total_loss, torch.Tensor) else avg_total_loss
        )
        self.val_loss_metrics['rec_loss'].update(
            avg_rec_loss.item() if isinstance(avg_rec_loss, torch.Tensor) else avg_rec_loss
        )
        self.val_loss_metrics['sim_loss'].update(
            avg_sim_loss.item() if isinstance(avg_sim_loss, torch.Tensor) else avg_sim_loss
        )
        
        # ë¡œê¹…
        self.log_dict({
            'val_total_loss': avg_total_loss,
            'val_rec_loss': avg_rec_loss,
            'val_sim_loss': avg_sim_loss,
            'val_subjects_processed': num_processed,
            'val_subject_num': subject_num,
            'val_batch_size': batch_size,
            # Placeholder metrics for Ray Tune compatibility (pretraining doesn't have classification)
            'val_macro_acc': 0.0,  # Will be replaced in fine-tuning phase
            'val_micro_acc': 0.0,  # Will be replaced in fine-tuning phase
            'val_acc': 0.0  # Required by Ray Tune AsyncHyperBandScheduler
        }, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)
        
        return avg_total_loss
    
    def _get_subject_val_batch(self, subject_id: str, subject_val_dataloader):
        """Subjectë³„ validation ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸° (trainingê³¼ ë™ì¼í•œ ë°©ì‹)"""
        
        # Validation iterator ê´€ë¦¬
        val_iterator_key = f"{subject_id}_val"
        if val_iterator_key not in self.subject_iterators:
            self.subject_iterators[val_iterator_key] = iter(subject_val_dataloader)
        
        try:
            # Subjectì—ì„œ validation ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
            batch = next(self.subject_iterators[val_iterator_key])
            return batch
        except StopIteration:
            # Iterator ì¬ì‹œì‘
            self.subject_iterators[val_iterator_key] = iter(subject_val_dataloader)
            try:
                batch = next(self.subject_iterators[val_iterator_key])
                return batch
            except StopIteration:
                return None
    
    def get_attention_weights(self, x: torch.Tensor) -> torch.Tensor:
        """ì‹œê°í™”ë¥¼ ìœ„í•œ attention weights ì¶”ì¶œ."""
        with torch.no_grad():
            # attention layerì— ì ‘ê·¼
            attention_layer = self.model.attention_layer
            x_weighted = attention_layer(x, x.shape[0], self.time_steps)
            
            # attention weights ê³„ì‚°
            x_reshape = torch.reshape(x, [-1, self.input_dim])
            attn_weights = F.softmax(
                torch.mm(x_reshape, attention_layer.w_linear) + 
                attention_layer.u_linear, 
                dim=1
            )
            attn_weights = torch.reshape(
                attn_weights, [x.shape[0], self.time_steps, self.input_dim]
            )
        
        return attn_weights