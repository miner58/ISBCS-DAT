"""
Analysis Pipeline Module

ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ì„ ìœ„í•œ í†µí•© íŒŒì´í”„ë¼ì¸
"""

import os
import glob
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, field
from pathlib import Path

import pandas as pd
import yaml

from .feature_extractor import FeatureExtractor, ExtractionConfig, FeatureData
from .tsne_visualizer import TSNEVisualizer, VisualizationConfig


@dataclass
class SubjectConfig:
    """í”¼í—˜ìë³„ ì„¤ì •"""
    subject_name: str
    checkpoint_path: str
    test_config_path: str
    model_name: str = "EEGNetLNL"


@dataclass
class ExperimentConfig:
    """ì‹¤í—˜ ì„¤ì •"""
    experiment_name: str
    analysis_result_path: str
    test_config_base_path: str
    output_dir: str
    max_subjects: Optional[int] = None


@dataclass 
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ í†µí•© ì„¤ì •"""
    extraction: ExtractionConfig
    visualization: VisualizationConfig
    save_intermediate: bool = True
    parallel_processing: bool = False


class AnalysisPipeline:
    """ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ í†µí•© íŒŒì´í”„ë¼ì¸"""
    
    def __init__(
        self,
        extraction_config: ExtractionConfig,
        visualization_config: VisualizationConfig = None
    ):
        self.extraction_config = extraction_config
        self.visualization_config = visualization_config or VisualizationConfig()
        
        self.extractor = FeatureExtractor(extraction_config)
        self.visualizer = TSNEVisualizer(self.visualization_config)
        
        self._results_cache = {}
    
    @classmethod
    def from_config_file(cls, config_path: str) -> 'AnalysisPipeline':
        """ì„¤ì • íŒŒì¼ì—ì„œ íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        with open(config_path, 'r') as f:
            config_data = yaml.safe_load(f)
        
        extraction_config = ExtractionConfig(**config_data.get('extraction', {}))
        visualization_config = VisualizationConfig(**config_data.get('visualization', {}))
        
        return cls(extraction_config, visualization_config)
    
    def run_single_subject_analysis(
        self,
        subject_config: SubjectConfig,
        output_dir: str,
        create_plots: bool = True
    ) -> Dict[str, Any]:
        """ë‹¨ì¼ í”¼í—˜ì ë¶„ì„"""
        print(f"ğŸ¯ í”¼í—˜ì ë¶„ì„: {subject_config.subject_name}")
        
        try:
            # ëª¨ë¸ ë¡œë“œ
            model = self.extractor.load_model_from_checkpoint(
                subject_config.checkpoint_path,
                subject_config.model_name
            )
            
            # ë°ì´í„° ëª¨ë“ˆ ìƒì„±
            aug_config = None
            if self.extraction_config.use_augmentation:
                aug_config = self.extractor.create_augmentation_config(
                    self.extraction_config.augmentation_config_path
                )
            
            from .feature_extractor import DataModuleFactory
            data_module = DataModuleFactory.create_data_module(
                subject_config.test_config_path,
                self.extraction_config.batch_size,
                self.extraction_config.test_data_path,
                aug_config
            )
            
            # íŠ¹ì§• ì¶”ì¶œ
            feature_data = self.extractor.extract_features(model, data_module)
            feature_data.subject_name = subject_config.subject_name
            feature_data.model_name = subject_config.model_name
            feature_data.checkpoint_path = subject_config.checkpoint_path
            
            # ê²°ê³¼ ì €ì¥
            output_path = os.path.join(output_dir, f"{subject_config.subject_name}_features.npz")
            self.extractor.save_features(feature_data, output_path)
            
            # ì‹œê°í™” ìƒì„±
            if create_plots:
                plot_output_dir = os.path.join(output_dir, "plots")
                self.visualizer.create_input_vs_feature_plot(feature_data, plot_output_dir)
            
            return {
                'status': 'success',
                'subject_name': subject_config.subject_name,
                'output_path': output_path,
                'feature_shape': feature_data.features.shape,
                'input_shape': feature_data.input_data.shape
            }
            
        except Exception as e:
            print(f"âŒ {subject_config.subject_name} ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'status': 'failed',
                'subject_name': subject_config.subject_name,
                'error': str(e)
            }
    
    def run_experiment_analysis(
        self,
        experiment_config: ExperimentConfig,
        create_combined_plots: bool = True
    ) -> Dict[str, Any]:
        """ì‹¤í—˜ ì „ì²´ ë¶„ì„"""
        print(f"ğŸš€ ì‹¤í—˜ ë¶„ì„: {experiment_config.experiment_name}")
        
        # ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        if not os.path.exists(experiment_config.analysis_result_path):
            raise FileNotFoundError(f"ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì—†ìŒ: {experiment_config.analysis_result_path}")
        
        df = pd.read_csv(experiment_config.analysis_result_path)
        valid_checkpoints = df[df['checkpoint_found'] == True].copy()
        
        if experiment_config.max_subjects:
            valid_checkpoints = valid_checkpoints.head(experiment_config.max_subjects)
        
        print(f"ğŸ“Š ì²˜ë¦¬í•  ì²´í¬í¬ì¸íŠ¸: {len(valid_checkpoints)}ê°œ")
        
        # í”¼í—˜ìë³„ ë¶„ì„
        results = []
        feature_data_list = []
        
        for _, checkpoint_info in valid_checkpoints.iterrows():
            subject_name = checkpoint_info['test_subject_name']
            checkpoint_path = checkpoint_info['checkpoint_path']
            
            # í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ì°¾ê¸°
            test_config_files = glob.glob(
                os.path.join(experiment_config.test_config_base_path, subject_name, "**", "*.json"),
                recursive=True
            )
            
            if not test_config_files:
                print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • ì—†ìŒ: {subject_name}")
                continue
            
            # ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
            model_info = self._extract_model_info_from_checkpoint(checkpoint_path)
            
            subject_config = SubjectConfig(
                subject_name=subject_name,
                checkpoint_path=checkpoint_path,
                test_config_path=test_config_files[0],
                model_name=model_info.get('model_name', 'EEGNetLNL')
            )
            
            # í”¼í—˜ì ë¶„ì„ ì‹¤í–‰
            subject_output_dir = os.path.join(experiment_config.output_dir, subject_name)
            result = self.run_single_subject_analysis(
                subject_config,
                subject_output_dir,
                create_plots=True
            )
            
            results.append(result)
            
            # ì„±ê³µí•œ ê²½ìš° íŠ¹ì§• ë°ì´í„° ìˆ˜ì§‘ (í†µí•© í”Œë¡¯ìš©)
            if result['status'] == 'success' and create_combined_plots:
                feature_data = self.visualizer.load_feature_data_from_npz(result['output_path'])
                feature_data_list.append(feature_data)
        
        # í†µí•© í”Œë¡¯ ìƒì„±
        if create_combined_plots and feature_data_list:
            print("ğŸ“Š í†µí•© í”Œë¡¯ ìƒì„±")
            combined_plot_dir = os.path.join(experiment_config.output_dir, "combined_plots")
            self.visualizer.create_combined_subjects_plot(
                feature_data_list,
                experiment_config.experiment_name,
                combined_plot_dir
            )
        
        # ê²°ê³¼ ìš”ì•½
        success_count = sum(1 for r in results if r['status'] == 'success')
        
        return {
            'experiment_name': experiment_config.experiment_name,
            'total_subjects': len(results),
            'success_count': success_count,
            'failed_count': len(results) - success_count,
            'results': results,
            'output_dir': experiment_config.output_dir
        }
    
    def run_augmentation_analysis(
        self,
        subject_configs: Union[SubjectConfig, List[SubjectConfig]],
        output_dir: str,
        plot_types: List[str] = None
    ) -> Dict[str, Any]:
        """ë°ì´í„° ì¦ê°• ë¶„ì„ - ë‹¨ì¼ ë˜ëŠ” ë‹¤ì¤‘ í”¼í—˜ì ì§€ì›"""
        if not self.extraction_config.use_augmentation:
            raise ValueError("ë°ì´í„° ì¦ê°•ì´ í™œì„±í™”ë˜ì§€ ì•ŠìŒ")
        
        plot_types = plot_types or ["type1", "type2", "type3"]
        
        # 1. ì…ë ¥ ì •ê·œí™”
        if isinstance(subject_configs, SubjectConfig):
            subject_configs = [subject_configs]
            is_single_subject = True
        else:
            is_single_subject = False
        
        subject_names = [sc.subject_name for sc in subject_configs]
        print(f"ğŸ¨ ë°ì´í„° ì¦ê°• ë¶„ì„: {subject_names}")
        
        try:
            # 2. ê° í”¼í—˜ìë³„ íŠ¹ì§• ì¶”ì¶œ
            original_feature_list = []
            augmented_feature_list = []
            individual_results = []
            
            for subject_config in subject_configs:
                print(f"  ğŸ¯ {subject_config.subject_name} ì²˜ë¦¬ ì¤‘...")
                
                # ëª¨ë¸ ë¡œë“œ
                model = self.extractor.load_model_from_checkpoint(
                    subject_config.checkpoint_path,
                    subject_config.model_name
                )
                
                from .feature_extractor import DataModuleFactory
                
                # ì›ë³¸ ë°ì´í„° ëª¨ë“ˆ (ì¦ê°• ì—†ìŒ)
                original_data_module = DataModuleFactory.create_data_module(
                    subject_config.test_config_path,
                    self.extraction_config.batch_size,
                    self.extraction_config.test_data_path,
                    None  # ì¦ê°• ì—†ìŒ
                )
                
                # ì¦ê°• ë°ì´í„° ëª¨ë“ˆ (ì¦ê°• ìˆìŒ)
                aug_config = self.extractor.create_augmentation_config(
                    self.extraction_config.augmentation_config_path
                )
                augmented_data_module = DataModuleFactory.create_data_module(
                    subject_config.test_config_path,
                    self.extraction_config.batch_size,
                    self.extraction_config.test_data_path,
                    aug_config
                )
                
                # íŠ¹ì§• ì¶”ì¶œ
                original_data = self.extractor.extract_features(model, original_data_module)
                augmented_data = self.extractor.extract_features(model, augmented_data_module)
                
                # ë©”íƒ€ë°ì´í„° ì„¤ì •
                original_data.subject_name = subject_config.subject_name
                original_data.model_name = subject_config.model_name
                original_data.checkpoint_path = subject_config.checkpoint_path
                
                augmented_data.subject_name = subject_config.subject_name
                augmented_data.model_name = subject_config.model_name
                augmented_data.checkpoint_path = subject_config.checkpoint_path
                
                original_feature_list.append(original_data)
                augmented_feature_list.append(augmented_data)
                
                # ê°œë³„ ê²°ê³¼ ì €ì¥
                individual_results.append({
                    'subject_name': subject_config.subject_name,
                    'original_shape': original_data.features.shape,
                    'augmented_shape': augmented_data.features.shape
                })
                
                print(f"    âœ… {subject_config.subject_name} íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ")
            
            # 3. NPZ íŒŒì¼ ì €ì¥
            os.makedirs(output_dir, exist_ok=True)
            original_paths = []
            augmented_paths = []
            
            for i, subject_config in enumerate(subject_configs):
                original_path = os.path.join(output_dir, f"{subject_config.subject_name}_original_features.npz")
                augmented_path = os.path.join(output_dir, f"{subject_config.subject_name}_augmented_features.npz")
                
                self.extractor.save_features(original_feature_list[i], original_path)
                self.extractor.save_features(augmented_feature_list[i], augmented_path)
                
                original_paths.append(original_path)
                augmented_paths.append(augmented_path)
            
            # 4. í†µí•© ì‹œê°í™” ìƒì„±
            plot_results = []
            
            if is_single_subject:
                print("  ğŸ“Š ë‹¨ì¼ í”¼í—˜ì ë°ì´í„° ì¦ê°• í”Œë¡¯ ìƒì„±")
                # ë‹¨ì¼ í”¼í—˜ì: ê¸°ì¡´ ë°©ì‹
                for plot_type in plot_types:
                    try:
                        fig = self.visualizer.create_augmentation_comparison_plot(
                            original_feature_list[0],
                            augmented_feature_list[0],
                            plot_type,
                            output_dir
                        )
                        plot_results.append(f"{plot_type}_plot_created")
                        print(f"    âœ… {plot_type} í”Œë¡¯ ìƒì„± ì™„ë£Œ")
                    except Exception as e:
                        print(f"    âš ï¸ {plot_type} í”Œë¡¯ ìƒì„± ì‹¤íŒ¨: {e}")
                        plot_results.append(f"{plot_type}_plot_failed")
            else:
                print("  ğŸ“Š ë‹¤ì¤‘ í”¼í—˜ì ë°ì´í„° ì¦ê°• í”Œë¡¯ ìƒì„±")
                # ë‹¤ì¤‘ í”¼í—˜ì: ìƒˆë¡œìš´ ë°©ì‹
                for plot_type in plot_types:
                    try:
                        # AugmentationComparisonPlot ì „ëµ ì§ì ‘ ì‚¬ìš©
                        strategy = self.visualizer._strategies['augmentation_comparison']
                        fig = strategy.create_plot(
                            original_feature_list,    # List[FeatureData]
                            augmented_feature_list,   # List[FeatureData]
                            plot_type=plot_type,
                            color_by="subject",       # í”¼í—˜ìë³„ ìƒ‰ìƒ
                            subject_name="MULTI"      # ë‹¤ì¤‘ í”¼í—˜ì ëª¨ë“œ
                        )
                        
                        # íŒŒì¼ëª… ìƒì„±
                        subject_names_str = "_".join(subject_names)
                        filename = f"multi_subject_augmentation_{plot_type}_{subject_names_str}"
                        strategy.save_plot(fig, output_dir, filename)
                        
                        plot_results.append(f"{plot_type}_plot_created")
                        print(f"    âœ… {plot_type} ë‹¤ì¤‘ í”¼í—˜ì í”Œë¡¯ ìƒì„± ì™„ë£Œ")
                        
                    except Exception as e:
                        print(f"    âš ï¸ {plot_type} ë‹¤ì¤‘ í”¼í—˜ì í”Œë¡¯ ìƒì„± ì‹¤íŒ¨: {e}")
                        plot_results.append(f"{plot_type}_plot_failed")
            
            # 5. í†µí•© NPZ íŒŒì¼ ì €ì¥ (ë‹¤ì¤‘ í”¼í—˜ìì¸ ê²½ìš°)
            combined_original_path = None
            combined_augmented_path = None
            
            if not is_single_subject:
                # ì—¬ëŸ¬ í”¼í—˜ì ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ ê²°í•©
                combined_original = self._combine_feature_data_list(original_feature_list)
                combined_augmented = self._combine_feature_data_list(augmented_feature_list)
                
                combined_original_path = os.path.join(output_dir, "combined_original_features.npz")
                combined_augmented_path = os.path.join(output_dir, "combined_augmented_features.npz")
                
                self.extractor.save_features(combined_original, combined_original_path)
                self.extractor.save_features(combined_augmented, combined_augmented_path)
                
                print(f"    ğŸ’¾ í†µí•© NPZ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
            
            # 6. ê²°ê³¼ ë°˜í™˜
            if is_single_subject:
                # ë‹¨ì¼ í”¼í—˜ì: ê¸°ì¡´ í˜¸í™˜ì„±
                return {
                    'status': 'success',
                    'subject_name': subject_configs[0].subject_name,
                    'original_path': original_paths[0],
                    'augmented_path': augmented_paths[0],
                    'plots_created': plot_results,
                    'original_shape': original_feature_list[0].features.shape,
                    'augmented_shape': augmented_feature_list[0].features.shape
                }
            else:
                # ë‹¤ì¤‘ í”¼í—˜ì: ìƒˆë¡œìš´ êµ¬ì¡°
                return {
                    'status': 'success',
                    'subject_names': subject_names,
                    'num_subjects': len(subject_configs),
                    'original_paths': original_paths,
                    'augmented_paths': augmented_paths,
                    'combined_original_path': combined_original_path,
                    'combined_augmented_path': combined_augmented_path,
                    'plots_created': plot_results,
                    'individual_results': individual_results,
                    'output_dir': output_dir
                }
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì¦ê°• ë¶„ì„ ì‹¤íŒ¨: {e}")
            if is_single_subject:
                return {
                    'status': 'failed',
                    'subject_name': subject_configs[0].subject_name,
                    'error': str(e)
                }
            else:
                return {
                    'status': 'failed',
                    'subject_names': subject_names,
                    'error': str(e)
                }

    
    def run_augmentation_experiment_analysis(
        self,
        experiment_config: ExperimentConfig,
        plot_types: List[str] = None,
        create_combined_plots: bool = True
    ) -> Dict[str, Any]:
        """ë°ì´í„° ì¦ê°• ì‹¤í—˜ ì „ì²´ ë¶„ì„"""
        print(f"ğŸ¨ ë°ì´í„° ì¦ê°• ì‹¤í—˜ ë¶„ì„: {experiment_config.experiment_name}")
        
        if not self.extraction_config.use_augmentation:
            raise ValueError("ë°ì´í„° ì¦ê°•ì´ í™œì„±í™”ë˜ì§€ ì•ŠìŒ")
        
        plot_types = plot_types or ["type1", "type2", "type3"]
        
        # ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        if not os.path.exists(experiment_config.analysis_result_path):
            raise FileNotFoundError(f"ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì—†ìŒ: {experiment_config.analysis_result_path}")
        
        df = pd.read_csv(experiment_config.analysis_result_path)
        valid_checkpoints = df[df['checkpoint_found'] == True].copy()
        
        if experiment_config.max_subjects:
            valid_checkpoints = valid_checkpoints.head(experiment_config.max_subjects)
        
        print(f"ğŸ“Š ì²˜ë¦¬í•  ì²´í¬í¬ì¸íŠ¸: {len(valid_checkpoints)}ê°œ")
        
        # í”¼í—˜ìë³„ ë°ì´í„° ì¦ê°• ë¶„ì„
        results = []
        original_feature_data_list = []
        augmented_feature_data_list = []
        
        for _, checkpoint_info in valid_checkpoints.iterrows():
            subject_name = checkpoint_info['test_subject_name']
            checkpoint_path = checkpoint_info['checkpoint_path']
            
            # í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ì°¾ê¸°
            test_config_files = glob.glob(
                os.path.join(experiment_config.test_config_base_path, subject_name, "**", "*.json"),
                recursive=True
            )
            
            if not test_config_files:
                print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì„¤ì • ì—†ìŒ: {subject_name}")
                continue
            
            # ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
            model_info = self._extract_model_info_from_checkpoint(checkpoint_path)
            
            subject_config = SubjectConfig(
                subject_name=subject_name,
                checkpoint_path=checkpoint_path,
                test_config_path=test_config_files[0],
                model_name=model_info.get('model_name', 'EEGNetLNL')
            )
            
            # ë°ì´í„° ì¦ê°• ë¶„ì„ ì‹¤í–‰
            subject_output_dir = os.path.join(experiment_config.output_dir, "augmentation_analysis", subject_name)
            result = self.run_augmentation_analysis(
                subject_config,
                subject_output_dir,
                plot_types
            )
            
            results.append(result)
            
            # ì„±ê³µí•œ ê²½ìš° íŠ¹ì§• ë°ì´í„° ìˆ˜ì§‘ (í†µí•© í”Œë¡¯ìš©)
            if result['status'] == 'success' and create_combined_plots:
                original_data = self.visualizer.load_feature_data_from_npz(result['original_path'])
                augmented_data = self.visualizer.load_feature_data_from_npz(result['augmented_path'])
                original_feature_data_list.append(original_data)
                augmented_feature_data_list.append(augmented_data)
        
        # í†µí•© ì¦ê°• ë¹„êµ í”Œë¡¯ ìƒì„±
        if create_combined_plots and original_feature_data_list and augmented_feature_data_list:
            print("ğŸ“Š í†µí•© ë°ì´í„° ì¦ê°• í”Œë¡¯ ìƒì„±")
            combined_plot_dir = os.path.join(experiment_config.output_dir, "combined_augmentation_plots")
            
            # 3ê°€ì§€ íƒ€ì…ë³„ë¡œ í†µí•© í”Œë¡¯ ìƒì„±
            for plot_type in plot_types:
                try:
                    # Strategy íŒ¨í„´ì„ ì‚¬ìš©í•œ ì¦ê°• ë¹„êµ í”Œë¡¯
                    strategy = self.visualizer._strategies['augmentation_comparison']
                    fig = strategy.create_plot(
                        original_feature_data_list,
                        augmented_feature_data_list,
                        plot_type=plot_type,
                        color_by="subject",  # í”¼í—˜ìë³„ ìƒ‰ìƒ êµ¬ë¶„
                        subject_name="ALL"   # ëª¨ë“  í”¼í—˜ì í†µí•©
                    )
                    
                    # í”Œë¡¯ ì €ì¥
                    filename = f"{experiment_config.experiment_name}_combined_augmentation_{plot_type}"
                    strategy.save_plot(fig, combined_plot_dir, filename)
                    
                    print(f"âœ… {plot_type} í†µí•© í”Œë¡¯ ì €ì¥ ì™„ë£Œ")
                    
                except Exception as e:
                    print(f"âš ï¸ {plot_type} í†µí•© í”Œë¡¯ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ê²°ê³¼ ìš”ì•½
        success_count = sum(1 for r in results if r['status'] == 'success')
        
        return {
            'experiment_name': experiment_config.experiment_name,
            'total_subjects': len(results),
            'success_count': success_count,
            'failed_count': len(results) - success_count,
            'plot_types': plot_types,
            'results': results,
            'output_dir': experiment_config.output_dir,
            'combined_plots_dir': os.path.join(experiment_config.output_dir, "combined_augmentation_plots") if create_combined_plots else None
        }

    def run_multi_experiment_analysis(
        self,
        base_directory: str,
        experiment_pattern: str = "**/analyzing_result",
        max_experiments: Optional[int] = None
    ) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ì‹¤í—˜ ë¶„ì„"""
        print(f"ğŸŒ ë‹¤ì¤‘ ì‹¤í—˜ ë¶„ì„: {base_directory}")
        
        # ì‹¤í—˜ ë””ë ‰í† ë¦¬ ì°¾ê¸°
        experiment_dirs = []
        for root, dirs, files in os.walk(base_directory):
            if 'analyzing_result' in dirs:
                analyzing_result_path = os.path.join(root, 'analyzing_result')
                checkpoint_analysis_file = os.path.join(analyzing_result_path, 'checkpoint_analysis_results.csv')
                
                if os.path.exists(checkpoint_analysis_file):
                    experiment_dirs.append({
                        'name': os.path.basename(root),
                        'path': analyzing_result_path,
                        'analysis_file': checkpoint_analysis_file
                    })
        
        if max_experiments:
            experiment_dirs = experiment_dirs[:max_experiments]
        
        print(f"ğŸ“Š ë°œê²¬ëœ ì‹¤í—˜: {len(experiment_dirs)}ê°œ")
        
        # ê° ì‹¤í—˜ ë¶„ì„
        experiment_results = []
        for exp_info in experiment_dirs:
            print(f"\nğŸ¯ ì‹¤í—˜ ì²˜ë¦¬: {exp_info['name']}")
            
            try:
                # ì‹¤í—˜ ì„¤ì • ìƒì„±
                experiment_config = ExperimentConfig(
                    experiment_name=exp_info['name'],
                    analysis_result_path=exp_info['analysis_file'],
                    test_config_base_path=self._infer_test_config_path(exp_info['name']),
                    output_dir=os.path.join(exp_info['path'], 'pipeline_results')
                )
                
                # ì‹¤í—˜ ë¶„ì„ ì‹¤í–‰
                result = self.run_experiment_analysis(experiment_config)
                experiment_results.append(result)
                
            except Exception as e:
                print(f"âŒ ì‹¤í—˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
                experiment_results.append({
                    'experiment_name': exp_info['name'],
                    'status': 'failed',
                    'error': str(e)
                })
        
        return {
            'total_experiments': len(experiment_results),
            'successful_experiments': sum(1 for r in experiment_results if r.get('success_count', 0) > 0),
            'results': experiment_results
        }
    
    def _extract_model_info_from_checkpoint(self, checkpoint_path: str) -> Dict:
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ"""
        yaml_files = glob.glob(os.path.join(os.path.dirname(checkpoint_path), '*.yml'))
        
        if not yaml_files:
            return {'model_name': 'EEGNetLNL', 'batch_size': self.extraction_config.batch_size}
        
        try:
            with open(yaml_files[0], 'r') as f:
                config = yaml.safe_load(f)
            
            search_space = config.get('search_space', {})
            return {
                'model_name': search_space.get('model_name', 'EEGNetLNL'),
                'batch_size': search_space.get('batch_size', self.extraction_config.batch_size)
            }
        except:
            return {'model_name': 'EEGNetLNL', 'batch_size': self.extraction_config.batch_size}
    
    def _infer_test_config_path(self, experiment_name: str) -> str:
        """ì‹¤í—˜ëª…ì—ì„œ í…ŒìŠ¤íŠ¸ ì„¤ì • ê²½ë¡œ ì¶”ë¡ """
        # ì‹¤í—˜ëª… íŒ¨í„´ì— ë”°ë¥¸ ê²½ë¡œ ë§¤í•‘
        if 'wire' in experiment_name.lower():
            return os.path.join(self.extraction_config.test_data_path, "data/raw3config/test/only1Day1,8")
        elif 'wireless' in experiment_name.lower():
            return os.path.join(self.extraction_config.test_data_path, "data/raw5&6config/test/only1Day1,8")
        elif 'ui' in experiment_name.lower():
            return os.path.join(self.extraction_config.test_data_path, "src/config/data_config/UIconfig/test")
        elif 'unm' in experiment_name.lower():
            return os.path.join(self.extraction_config.test_data_path, "src/config/data_config/UNMconfig/test")
        else:
            # ê¸°ë³¸ê°’
            return os.path.join(self.extraction_config.test_data_path, "data/raw5&6config/test/only1Day1,8")
    
    def _combine_feature_data_list(self, feature_data_list: List) -> 'FeatureData':
        """ë‹¤ì¤‘ FeatureDataë¥¼ í•˜ë‚˜ë¡œ ê²°í•©"""
        from .feature_extractor import FeatureData
        import numpy as np
        
        if len(feature_data_list) == 1:
            return feature_data_list[0]
        
        # ëª¨ë“  ë°ì´í„° ê²°í•©
        combined_features = np.vstack([fd.features for fd in feature_data_list])
        combined_target_labels = np.hstack([fd.target_labels for fd in feature_data_list])
        combined_input_data = np.vstack([fd.input_data for fd in feature_data_list])
        
        # Subject ë¼ë²¨ ìƒì„±
        combined_subject_labels = []
        subject_names = []
        
        for i, fd in enumerate(feature_data_list):
            subject_names.append(fd.subject_name)
            combined_subject_labels.extend([i] * len(fd.target_labels))
        
        # ë„ë©”ì¸ ë¼ë²¨ ê²°í•© (ìˆëŠ” ê²½ìš°)
        combined_domain_labels = None
        if all(fd.domain_labels is not None for fd in feature_data_list):
            combined_domain_labels = np.hstack([fd.domain_labels for fd in feature_data_list])
        
        # ë©”íƒ€ë°ì´í„° ì„¤ì •
        first_fd = feature_data_list[0]
        
        return FeatureData(
            features=combined_features,
            target_labels=combined_target_labels,
            input_data=combined_input_data,
            domain_labels=combined_domain_labels,
            subject_name="COMBINED",
            model_name=first_fd.model_name,
            checkpoint_path=first_fd.checkpoint_path,
            metadata={
                'subject_names': subject_names,
                'subject_labels': np.array(combined_subject_labels),
                'num_subjects': len(feature_data_list)
            }
        )