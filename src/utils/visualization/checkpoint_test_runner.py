"""
RayTune ì²´í¬í¬ì¸íŠ¸ì—ì„œ íŠ¹ì§• ì¶”ì¶œ ë° ì €ì¥ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë“ˆ

ì£¼ìš” ê¸°ëŠ¥:
1. checkpoint_analysis_results.csvì—ì„œ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë¡œë“œ
2. ì²´í¬í¬ì¸íŠ¸ë¡œë¶€í„° ëª¨ë¸ ë³µì›
3. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ ë° ì €ì¥
"""
import os
import sys
import json
import glob
import yaml
import torch
import pandas as pd
import numpy as np
import pytorch_lightning as pl
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# ëª¨ë¸ ë° ë°ì´í„° ëª¨ë“ˆ import
from src.models import EEGNet
from src.models.eegnet_grl import EEGNetGRL, EEGNetLNL, EEGNetMI, EEGNetLNLAutoCorrelation
from src.models.eegnetDRO import EEGNetDRO
from src.models.eegnet_grl_lag import EEGNetLNLLag
from src.data.modules.EEGdataModuel import EEGDataModule


class FeatureExtractor:
    """ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self, test_data_default_path: str):
        self.test_data_default_path = test_data_default_path
        self.model_dict = {
            'EEGNet': EEGNet,
            'EEGNetDomainAdaptation_LNL': EEGNetLNL,
            'EEGNetDomainAdaptation_Not_GRL': EEGNetMI,
            'EEGNetDomainAdaptation_Only_GRL': EEGNetGRL,
            'EEGNetLNL': EEGNetLNL,
            'EEGNetMI': EEGNetMI,
            'EEGNetGRL': EEGNetGRL,
            'EEGNetLNLLag': EEGNetLNLLag,
            'EEGNetLNLAutoCorrelation': EEGNetLNLAutoCorrelation,
            'EEGNetDRO': EEGNetDRO
        }
    
    def load_model_from_checkpoint(self, checkpoint_path: str, model_name: str):
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ"""
        model_class = self.model_dict.get(model_name)
        if not model_class:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model_name}")
        
        ckpt_file = os.path.join(checkpoint_path, "checkpoint.ckpt")
        if not os.path.exists(ckpt_file):
            raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ckpt_file}")
        
        print(f"ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ: {ckpt_file}")
        model = model_class.load_from_checkpoint(ckpt_file)
        model.eval()
        return model
    
    def create_data_module(self, test_config_path: str, batch_size: int = 16):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ëª¨ë“ˆ ìƒì„±"""
        # ê²½ë¡œ ë³´ì •
        config_path = test_config_path
        old_base = "/mnt/sdb1/jsw/hanseul/code/Fairness_for_generalization"
        new_base = "/home/jsw/Fairness/Fairness_for_generalization"
        
        if config_path.startswith(old_base):
            relative_path = os.path.relpath(config_path, old_base)
            config_path = os.path.join(new_base, relative_path)
        
        with open(config_path, 'r') as f:
            data_config = json.load(f)
        
        data_module = EEGDataModule(
            data_config=data_config, batch_size=batch_size, masking_ch_list=[],
            rm_ch_list=[], subject_usage="test1", seed=None,
            default_path=self.test_data_default_path, skip_time_list=None
        )
        
        data_module.setup('test')
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data_module.test_dataset)}ê°œ ìƒ˜í”Œ")
        return data_module
    
    def extract_features(self, model, data_module) -> Tuple[np.ndarray, np.ndarray]:
        """ëª¨ë¸ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
        model.eval()
        all_features = []
        all_labels = []
        
        with torch.no_grad():
            for batch in data_module.test_dataloader():
                x, labels = batch
                
                # GPU ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ì´ë™
                if torch.cuda.is_available():
                    x = x.cuda()
                    model = model.cuda()
                
                # íŠ¹ì§• ì¶”ì¶œ (extract_features ë©”ì„œë“œ ì‚¬ìš©)
                if hasattr(model, 'extract_features'):
                    features = model.extract_features(x)
                else:
                    # extract_featuresê°€ ì—†ëŠ” ê²½ìš° forwardë¡œ íŠ¹ì§• ì¶”ì¶œ
                    features = model.feature_extractor(x.permute(0, 3, 1, 2))
                    features = torch.flatten(features, start_dim=1)
                
                all_features.append(features.cpu().numpy())
                all_labels.append(labels.numpy())
        
        features_array = np.vstack(all_features)
        labels_array = np.hstack(all_labels)
        
        print(f"âœ… íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {features_array.shape}")
        return features_array, labels_array


class CheckpointFeatureRunner:
    """ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ ì‹¤í–‰ê¸°"""
    
    def __init__(self, analysis_result_path: str, test_config_base_path: str, test_data_default_path: str):
        self.analysis_result_path = analysis_result_path
        self.test_config_base_path = test_config_base_path
        self.extractor = FeatureExtractor(test_data_default_path)
    
    def load_analysis_results(self) -> pd.DataFrame:
        """ë¶„ì„ ê²°ê³¼ ë¡œë“œ"""
        df = pd.read_csv(self.analysis_result_path)
        valid_df = df[df['checkpoint_found'] == True].copy()
        print(f"ğŸ“‹ ìœ íš¨í•œ ì²´í¬í¬ì¸íŠ¸: {len(valid_df)}ê°œ")
        return valid_df
    
    def get_test_config_files(self, subject_name: str) -> List[str]:
        """í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ì°¾ê¸°"""
        subject_path = os.path.join(self.test_config_base_path, subject_name)
        if not os.path.exists(subject_path):
            return []
        return glob.glob(os.path.join(subject_path, '**', '*.json'), recursive=True)
    
    def extract_model_info(self, experiment_path: str) -> Dict:
        """ëª¨ë¸ ì •ë³´ ì¶”ì¶œ"""
        yaml_files = glob.glob(os.path.join(os.path.dirname(experiment_path), '*.yml'))
        if not yaml_files:
            return {'model_name': 'EEGNetLNL', 'batch_size': 16}
        
        try:
            with open(yaml_files[0], 'r') as f:
                config = yaml.safe_load(f)
            search_space = config.get('search_space', {})
            return {
                'model_name': search_space.get('model_name', 'EEGNetLNL'),
                'batch_size': search_space.get('batch_size', 16)
            }
        except:
            return {'model_name': 'EEGNetLNL', 'batch_size': 16}
    
    def run_single_extraction(self, checkpoint_info: pd.Series, output_dir: str) -> bool:
        """ë‹¨ì¼ ì²´í¬í¬ì¸íŠ¸ íŠ¹ì§• ì¶”ì¶œ"""
        subject_name = checkpoint_info['test_subject_name']
        checkpoint_path = checkpoint_info['checkpoint_path']
        experiment_path = checkpoint_info['experiment_path']
        
        print(f"\nğŸ¯ íŠ¹ì§• ì¶”ì¶œ ì‹œì‘: {subject_name}")
        
        # ëª¨ë¸ ì •ë³´ ë° ì„¤ì • íŒŒì¼
        model_info = self.extract_model_info(experiment_path)
        test_config_files = self.get_test_config_files(subject_name)
        
        if not test_config_files:
            print(f"âŒ {subject_name} í…ŒìŠ¤íŠ¸ ì„¤ì • ì—†ìŒ")
            return False
        
        try:
            # ëª¨ë¸ ë¡œë“œ ë° ë°ì´í„° ì¤€ë¹„
            model = self.extractor.load_model_from_checkpoint(checkpoint_path, model_info['model_name'])
            data_module = self.extractor.create_data_module(test_config_files[0], model_info['batch_size'])
            
            # íŠ¹ì§• ì¶”ì¶œ
            features, labels = self.extractor.extract_features(model, data_module)
            
            # ì €ì¥
            output_file = os.path.join(output_dir, f"{subject_name}_features.npz")
            os.makedirs(output_dir, exist_ok=True)
            
            np.savez_compressed(output_file, 
                              features=features, 
                              labels=labels,
                              subject_name=subject_name,
                              model_name=model_info['model_name'],
                              checkpoint_path=checkpoint_path)
            
            print(f"ğŸ’¾ íŠ¹ì§• ì €ì¥: {output_file} (shape: {features.shape})")
            return True
            
        except Exception as e:
            print(f"âŒ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return False
    
    def run_all_extractions(self, output_base_dir: str, max_extractions: Optional[int] = None) -> Dict:
        """ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ íŠ¹ì§• ì¶”ì¶œ"""
        print("ğŸš€ íŠ¹ì§• ì¶”ì¶œ ì‹œì‘\n")
        
        valid_checkpoints = self.load_analysis_results()
        if max_extractions:
            valid_checkpoints = valid_checkpoints.head(max_extractions)
        
        results = {'success': [], 'failed': []}
        
        for idx, checkpoint_info in valid_checkpoints.iterrows():
            subject_name = checkpoint_info['test_subject_name']
            output_dir = os.path.join(output_base_dir, subject_name)
            
            if self.run_single_extraction(checkpoint_info, output_dir):
                results['success'].append(subject_name)
            else:
                results['failed'].append(subject_name)
        
        print(f"\nğŸ“Š íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: ì„±ê³µ {len(results['success'])}ê°œ, ì‹¤íŒ¨ {len(results['failed'])}ê°œ")
        return results


def extract_checkpoint_features(analysis_result_path: str, test_config_base_path: str, 
                               test_data_default_path: str, output_dir: str, 
                               max_extractions: Optional[int] = None) -> Dict:
    """ì²´í¬í¬ì¸íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì‹¤í–‰ í•¨ìˆ˜"""
    runner = CheckpointFeatureRunner(
        analysis_result_path=analysis_result_path,
        test_config_base_path=test_config_base_path,
        test_data_default_path=test_data_default_path
    )
    
    return runner.run_all_extractions(output_dir, max_extractions)


if __name__ == "__main__":
    print("ğŸš€ ì²´í¬í¬ì¸íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì‹œìŠ¤í…œ")
    
    # ê¸°ë³¸ ì„¤ì •
    analysis_result_path = "/home/jsw/Fairness/tmp/Fairness_for_generalization/results_trans/analyzing_result/checkpoint_analysis_results.csv"
    test_config_base_path = "/home/jsw/Fairness/tmp/Fairness_for_generalization/data/raw3config/test/only1Day1,8"
    test_data_default_path = "/home/jsw/Fairness/tmp/Fairness_for_generalization/data/preprocessed/at_least"
    output_dir = "/home/jsw/Fairness/tmp/Fairness_for_generalization/extracted_features"
    
    try:
        results = extract_checkpoint_features(
            analysis_result_path=analysis_result_path,
            test_config_base_path=test_config_base_path,
            test_data_default_path=test_data_default_path,
            output_dir=output_dir,
            max_extractions=3
        )
        print(f"âœ… íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ: {results}")
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    
    def load_analysis_results(self) -> pd.DataFrame:
        """ì²´í¬í¬ì¸íŠ¸ ë¶„ì„ ê²°ê³¼ ë¡œë“œ"""
        if not os.path.exists(self.analysis_result_path):
            raise FileNotFoundError(f"ë¶„ì„ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.analysis_result_path}")
        
        df = pd.read_csv(self.analysis_result_path)
        print(f"ğŸ“‹ ë¶„ì„ ê²°ê³¼ ë¡œë“œ: {len(df)}ê°œ ì²´í¬í¬ì¸íŠ¸")
        
        # ìœ íš¨í•œ ì²´í¬í¬ì¸íŠ¸ë§Œ í•„í„°ë§
        valid_df = df[df['checkpoint_found'] == True].copy()
        print(f"âœ… ìœ íš¨í•œ ì²´í¬í¬ì¸íŠ¸: {len(valid_df)}ê°œ")
        
        return valid_df
    
    def get_test_config_files(self, subject_name: str) -> List[str]:
        """ì£¼ì²´ë³„ í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ì°¾ê¸°"""
        subject_path = os.path.join(self.test_config_base_path, subject_name)
        if not os.path.exists(subject_path):
            print(f"âš ï¸ ì£¼ì²´ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {subject_path}")
            return []
        
        # ì¬ê·€ì ìœ¼ë¡œ JSON íŒŒì¼ ì°¾ê¸°
        config_files = glob.glob(os.path.join(subject_path, '**', '*.json'), recursive=True)
        print(f"ğŸ“ {subject_name} í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼: {len(config_files)}ê°œ")
        
        return config_files
    
    def extract_model_info_from_path(self, experiment_path: str) -> Dict:
        """ì‹¤í—˜ ê²½ë¡œì—ì„œ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ"""
        # ì‹¤í—˜ í´ë”ì—ì„œ YAML ì„¤ì • íŒŒì¼ ì°¾ê¸°
        yaml_files = glob.glob(os.path.join(os.path.dirname(experiment_path), '*.yml'))
        if not yaml_files:
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                'model_name': 'EEGNetLNL',  # ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸
                'batch_size': 16
            }
        
        try:
            with open(yaml_files[0], 'r') as f:
                config = yaml.safe_load(f)
            
            # search_spaceì—ì„œ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
            search_space = config.get('search_space', {})
            return {
                'model_name': search_space.get('model_name', 'EEGNetLNL'),
                'batch_size': search_space.get('batch_size', 16)
            }
        except Exception as e:
            print(f"âš ï¸ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {
                'model_name': 'EEGNetLNL',
                'batch_size': 16
            }
    
    def run_single_test(self, checkpoint_info: pd.Series) -> Dict:
        """ë‹¨ì¼ ì²´í¬í¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        subject_name = checkpoint_info['test_subject_name']
        checkpoint_path = checkpoint_info['checkpoint_path']
        experiment_path = checkpoint_info['experiment_path']
        
        print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ì‹œì‘: {subject_name}")
        print(f"   ì²´í¬í¬ì¸íŠ¸: {os.path.basename(checkpoint_path)}")
        
        # ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
        model_info = self.extract_model_info_from_path(experiment_path)
        model_name = model_info['model_name']
        batch_size = model_info['batch_size']
        
        # í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ì°¾ê¸°
        test_config_files = self.get_test_config_files(subject_name)
        if not test_config_files:
            print(f"âŒ {subject_name}ì˜ í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        # ëª¨ë¸ ë¡œë“œ
        try:
            model = self.tester.load_model_from_checkpoint(checkpoint_path, model_name)
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
        
        # ê° í…ŒìŠ¤íŠ¸ ì„¤ì •ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        all_results = []
        for config_file in test_config_files[:1]:  # ì²« ë²ˆì§¸ ì„¤ì •ë§Œ ì‚¬ìš© (ì‹œê°„ ë‹¨ì¶•)
            try:
                data_module = self.tester.create_data_module(config_file, batch_size)
                test_results = self.tester.run_test(model, data_module)
                
                # ê²°ê³¼ì— ë©”íƒ€ ì •ë³´ ì¶”ê°€
                test_results.update({
                    'subject_name': subject_name,
                    'test_config': os.path.basename(config_file),
                    'model_name': model_name,
                    'checkpoint_path': checkpoint_path,
                    'grl_lambda': checkpoint_info['grl_lambda'],
                    'lnl_lambda': checkpoint_info['lnl_lambda']
                })
                
                all_results.append(test_results)
                
            except Exception as e:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                continue
        
        return all_results[0] if all_results else {}
    
    def run_all_tests(self, max_tests: Optional[int] = None) -> pd.DataFrame:
        """ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ ì²´í¬í¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
        
        # ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        valid_checkpoints = self.load_analysis_results()
        
        if max_tests:
            valid_checkpoints = valid_checkpoints.head(max_tests)
            print(f"ğŸ”¢ í…ŒìŠ¤íŠ¸ ì œí•œ: {max_tests}ê°œ")
        
        # ê° ì²´í¬í¬ì¸íŠ¸ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_results = []
        for idx, checkpoint_info in valid_checkpoints.iterrows():
            try:
                result = self.run_single_test(checkpoint_info)
                if result:
                    test_results.append(result)
                    print(f"âœ… {checkpoint_info['test_subject_name']} í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                else:
                    print(f"âŒ {checkpoint_info['test_subject_name']} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            except Exception as e:
                print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        results_df = pd.DataFrame(test_results)
        
        print(f"\nğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(results_df)}/{len(valid_checkpoints)}ê°œ ì„±ê³µ")
        
        return results_df
    
    def save_results(self, results_df: pd.DataFrame, output_path: str):
        """ê²°ê³¼ ì €ì¥"""
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        results_df.to_csv(output_path, index=False)
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")


def run_checkpoint_tests(analysis_result_path: str, test_config_base_path: str, 
                        test_data_default_path: str, output_path: str, 
                        max_tests: Optional[int] = None):
    """
    ì²´í¬í¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        analysis_result_path: checkpoint_analysis_results.csv íŒŒì¼ ê²½ë¡œ
        test_config_base_path: í…ŒìŠ¤íŠ¸ ì„¤ì • íŒŒì¼ ê¸°ë³¸ ê²½ë¡œ
        test_data_default_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ë³¸ ê²½ë¡œ
        output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        max_tests: ìµœëŒ€ í…ŒìŠ¤íŠ¸ ìˆ˜ (Noneì´ë©´ ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸)
    """
    runner = CheckpointFeatureRunner(
        analysis_result_path=analysis_result_path,
        test_config_base_path=test_config_base_path,
        test_data_default_path=test_data_default_path
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results_df = runner.run_all_tests(max_tests=max_tests)
    
    # ê²°ê³¼ ì €ì¥
    if not results_df.empty:
        runner.save_results(results_df, output_path)
        
        # ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
        print(f"\nğŸ“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í†µê³„:")
        if 'test/report/macro avg/accuracy' in results_df.columns:
            acc_col = 'test/report/macro avg/accuracy'
            print(f"   í‰ê·  ì •í™•ë„: {results_df[acc_col].mean():.4f}")
            print(f"   ìµœê³  ì •í™•ë„: {results_df[acc_col].max():.4f}")
            print(f"   ìµœì € ì •í™•ë„: {results_df[acc_col].min():.4f}")
    else:
        print("âŒ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    return results_df


def run_batch_checkpoint_tests(base_experiment_paths: List[str], 
                              test_config_mapping: Dict[str, str],
                              test_data_default_path: str,
                              max_tests_per_experiment: Optional[int] = None):
    """
    ì—¬ëŸ¬ ì‹¤í—˜ì— ëŒ€í•´ ì¼ê´„ ì²´í¬í¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    
    Args:
        base_experiment_paths: ì‹¤í—˜ ê¸°ë³¸ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        test_config_mapping: ë°ì´í„° íƒ€ì…ë³„ í…ŒìŠ¤íŠ¸ ì„¤ì • ê²½ë¡œ ë§¤í•‘
        test_data_default_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ë³¸ ê²½ë¡œ
        max_tests_per_experiment: ì‹¤í—˜ë‹¹ ìµœëŒ€ í…ŒìŠ¤íŠ¸ ìˆ˜
    
    Example:
        test_config_mapping = {
            'wire': '/path/to/raw3config/test/only1Day1,8',
            'wireless': '/path/to/raw5&6config/test/only1Day1,8'
        }
    """
    all_results = []
    
    for base_path in base_experiment_paths:
        print(f"\nğŸ¯ ì‹¤í—˜ ê¸°ë³¸ ê²½ë¡œ ì²˜ë¦¬: {base_path}")
        
        # ì‹¤í—˜ íƒ€ì…ë³„ë¡œ ì²˜ë¦¬
        for data_type, test_config_path in test_config_mapping.items():
            print(f"ğŸ“Š ë°ì´í„° íƒ€ì…: {data_type}")
            
            # í•´ë‹¹ íƒ€ì…ì˜ ì‹¤í—˜ í´ë” ì°¾ê¸°
            experiment_folders = []
            if data_type == "wire":
                patterns = ["*2_inner_wire*", "*3_wireless2wire*"]
            elif data_type == "wireless":
                patterns = ["*1_inner_wireless*", "*4_wire2wireless*"]
            else:
                print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„° íƒ€ì…: {data_type}")
                continue
            
            # íŒ¨í„´ì— ë§ëŠ” í´ë” ì°¾ê¸°
            for pattern in patterns:
                matching_folders = glob.glob(os.path.join(base_path, pattern))
                experiment_folders.extend(matching_folders)
            
            print(f"ğŸ“ {data_type} ì‹¤í—˜ í´ë”: {len(experiment_folders)}ê°œ")
            
            # ê° ì‹¤í—˜ í´ë”ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            for exp_folder in experiment_folders:
                ray_results_folders = glob.glob(os.path.join(exp_folder, "ray_results*"))
                
                for ray_folder in ray_results_folders:
                    analysis_result_path = os.path.join(ray_folder, "analyzing_result", "checkpoint_analysis_results.csv")
                    output_path = os.path.join(ray_folder, "analyzing_result", "checkpoint_test_results.csv")
                    
                    if os.path.exists(analysis_result_path):
                        try:
                            print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰: {os.path.basename(ray_folder)}")
                            results = run_checkpoint_tests(
                                analysis_result_path=analysis_result_path,
                                test_config_base_path=test_config_path,
                                test_data_default_path=test_data_default_path,
                                output_path=output_path,
                                max_tests=max_tests_per_experiment
                            )
                            
                            if not results.empty:
                                # ì‹¤í—˜ ë©”íƒ€ ì •ë³´ ì¶”ê°€
                                results['experiment_folder'] = exp_folder
                                results['data_type'] = data_type
                                all_results.append(results)
                                
                        except Exception as e:
                            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                            continue
                    else:
                        print(f"âš ï¸ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì—†ìŒ: {analysis_result_path}")
    
    # ì „ì²´ ê²°ê³¼ í†µí•©
    if all_results:
        combined_results = pd.concat(all_results, ignore_index=True)
        print(f"\nğŸ‰ ì „ì²´ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
        print(f"   ì´ í…ŒìŠ¤íŠ¸: {len(combined_results)}ê°œ")
        print(f"   ì‹¤í—˜ í´ë”: {combined_results['experiment_folder'].nunique()}ê°œ")
        
        # ì „ì²´ ê²°ê³¼ ì €ì¥
        batch_output_path = "/tmp/batch_checkpoint_test_results.csv"
        combined_results.to_csv(batch_output_path, index=False)
        print(f"ğŸ’¾ ë°°ì¹˜ ê²°ê³¼ ì €ì¥: {batch_output_path}")
        
        return combined_results
    else:
        print("âŒ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()


if __name__ == "__main__":
    # ì˜ˆì‹œ ì‹¤í–‰
    analysis_result_path = "/home/jsw/Fairness/tmp/Fairness_for_generalization/results_trans/results_trans/results_subject_60/1_inner_wireless/ray_results_test1_Day1,8_finetune_ReduceLROnPlateau_LNL_batch16/analyzing_result/checkpoint_analysis_results.csv"
    test_config_base_path = "/home/jsw/Fairness/tmp/Fairness_for_generalization/data/raw5&6config/test/only1Day1,8"
    test_data_default_path = "/home/jsw/Fairness/tmp/Fairness_for_generalization"
    output_path = "/home/jsw/Fairness/tmp/Fairness_for_generalization/results_trans/results_trans/results_subject_60/1_inner_wireless/ray_results_test1_Day1,8_finetune_ReduceLROnPlateau_LNL_batch16/analyzing_result/checkpoint_test_results.csv"
    
    try:
        results = run_checkpoint_tests(
            analysis_result_path=analysis_result_path,
            test_config_base_path=test_config_base_path,
            test_data_default_path=test_data_default_path,
            output_path=output_path,
            max_tests=3  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 3ê°œë§Œ ì‹¤í–‰
        )
        print("âœ… ì²´í¬í¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
