"""
Input vs Feature t-SNE ë¹„êµ ì‹œê°í™” ëª¨ë“ˆ

ì¶”ì¶œëœ NPZ íŒŒì¼ì—ì„œ input_dataì™€ featuresë¥¼ ë¡œë“œí•˜ì—¬ t-SNE ë¹„êµ ì‹œê°í™”
"""
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from typing import Dict, List, Tuple, Optional
import glob
import warnings
warnings.filterwarnings('ignore')


def load_extracted_features(npz_file_path: str) -> Dict:
    """NPZ íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    data = np.load(npz_file_path)
    return {
        'input_data': data['input_data'],
        'features': data['features'], 
        'target_labels': data['target_labels'],
        'domain_labels': data.get('domain_labels', None),
        'subject_name': str(data['subject_name']),
        'model_name': str(data['model_name'])
    }


def load_extracted_features_with_predictions(npz_file_path: str) -> Dict:
    """ì˜ˆì¸¡ ì •ë³´ë¥¼ í¬í•¨í•œ NPZ íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    data = np.load(npz_file_path)
    result = {
        'input_data': data['input_data'],
        'features': data['features'], 
        'target_labels': data['target_labels'],
        'subject_name': str(data['subject_name']),
        'model_name': str(data['model_name'])
    }
    
    # ì˜ˆì¸¡ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
    if 'predictions' in data:
        result.update({
            'predictions': data['predictions'],
            'prediction_probs': data['prediction_probs'],
            'correct_predictions': data['correct_predictions'],
            'accuracy': float(data['accuracy']),
            'per_class_accuracy': eval(str(data['per_class_accuracy'])) if 'per_class_accuracy' in data else {}
        })
    
    # ë„ë©”ì¸ ë¼ë²¨ì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
    if 'domain_labels' in data and data['domain_labels'] is not None:
        result['domain_labels'] = data['domain_labels']
    
    return result


def plot_prediction_accuracy_tsne(data_dict: Dict, save_path: Optional[str] = None):
    """ì˜ˆì¸¡ ì •í™•ë„ì— ë”°ë¥¸ ìƒ‰ìƒ êµ¬ë¶„ t-SNE (Type A)"""
    features = data_dict['features']
    target_labels = data_dict['target_labels'] 
    correct_predictions = data_dict['correct_predictions']
    subject_name = data_dict['subject_name']
    model_name = data_dict['model_name']
    accuracy = data_dict['accuracy']
    
    print(f"ğŸ¯ {subject_name} ì˜ˆì¸¡ ì •í™•ë„ t-SNE ì‹œì‘ (ì •í™•ë„: {accuracy:.4f})")
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    
    # t-SNE ìˆ˜í–‰
    perplexity_val = min(30, features.shape[0] - 1)
    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity_val, 
               max_iter=1000, init='pca', learning_rate='auto')
    features_tsne = tsne.fit_transform(features_scaled)
    
    # ì‹œê°í™”
    sns.set_theme(style="white", context="notebook")
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ
    unique_labels = np.unique(target_labels)
    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}
    
    # ì •í™•í•œ ì˜ˆì¸¡: ì§„í•œ ìƒ‰ìƒ + ì›í˜• ë§ˆì»¤, í‹€ë¦° ì˜ˆì¸¡: ì—°í•œ ìƒ‰ìƒ + X ë§ˆì»¤
    for class_id in unique_labels:
        class_mask = target_labels == class_id
        
        # ì •í™•í•œ ì˜ˆì¸¡
        correct_mask = class_mask & correct_predictions
        if np.any(correct_mask):
            ax.scatter(features_tsne[correct_mask, 0], features_tsne[correct_mask, 1],
                      c=[color_map[class_id]], marker='o', s=60, alpha=0.8,
                      label=f'Class {class_id} (Correct)', edgecolors='black', linewidth=0.5)
        
        # í‹€ë¦° ì˜ˆì¸¡  
        incorrect_mask = class_mask & ~correct_predictions
        if np.any(incorrect_mask):
            ax.scatter(features_tsne[incorrect_mask, 0], features_tsne[incorrect_mask, 1],
                      c=[color_map[class_id]], marker='x', s=100, alpha=0.9,
                      label=f'Class {class_id} (Wrong)', linewidths=3)
    
    ax.set_title(f'Prediction Accuracy Analysis\n{subject_name} ({model_name}) - Accuracy: {accuracy:.4f}', 
                fontweight='bold', fontsize=12)
    ax.legend(frameon=False)
    ax.set_xticks([])
    ax.set_yticks([])
    sns.despine(ax=ax, left=True, bottom=True)
    
    plt.tight_layout()
    
    # ì €ì¥
    if save_path:
        base_filename = f"{subject_name}_prediction_accuracy_tsne"
        
        # PNG ì €ì¥
        png_filename = f"{base_filename}.png"
        plt.savefig(os.path.join(save_path, png_filename), dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ PNG ì €ì¥: {png_filename}")
        
        # SVG ì €ì¥
        svg_filename = f"{base_filename}.svg"
        plt.savefig(os.path.join(save_path, svg_filename), format='svg', bbox_inches='tight')
        print(f"ğŸ’¾ SVG ì €ì¥: {svg_filename}")
    
    plt.show()


def plot_prediction_confidence_tsne(data_dict: Dict, save_path: Optional[str] = None):
    """ì˜ˆì¸¡ ì‹ ë¢°ë„ì— ë”°ë¥¸ í¬ê¸° êµ¬ë¶„ t-SNE (Type B)"""
    features = data_dict['features']
    target_labels = data_dict['target_labels']
    prediction_probs = data_dict['prediction_probs']
    correct_predictions = data_dict['correct_predictions']
    subject_name = data_dict['subject_name']
    model_name = data_dict['model_name']
    accuracy = data_dict['accuracy']
    
    print(f"ğŸ¯ {subject_name} ì˜ˆì¸¡ ì‹ ë¢°ë„ t-SNE ì‹œì‘")
    
    # ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚° (ìµœëŒ€ í™•ë¥ ê°’)
    confidence = np.max(prediction_probs, axis=1)
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    
    # t-SNE ìˆ˜í–‰
    perplexity_val = min(30, features.shape[0] - 1)
    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity_val,
               max_iter=1000, init='pca', learning_rate='auto')
    features_tsne = tsne.fit_transform(features_scaled)
    
    # ì‹œê°í™”
    sns.set_theme(style="white", context="notebook")
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ
    unique_labels = np.unique(target_labels)
    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}
    
    for class_id in unique_labels:
        class_mask = target_labels == class_id
        
        # ì •í™•í•œ ì˜ˆì¸¡ (ì›í˜• ë§ˆì»¤, ì‹ ë¢°ë„ì— ë¹„ë¡€í•˜ëŠ” í¬ê¸°)
        correct_mask = class_mask & correct_predictions
        if np.any(correct_mask):
            ax.scatter(features_tsne[correct_mask, 0], features_tsne[correct_mask, 1],
                      c=[color_map[class_id]], s=confidence[correct_mask] * 200,  # ì‹ ë¢°ë„ì— ë¹„ë¡€í•˜ëŠ” í¬ê¸°
                      alpha=0.7, marker='o', edgecolors='black', linewidth=0.5,
                      label=f'Class {class_id} (Correct)')
        
        # í‹€ë¦° ì˜ˆì¸¡ (ì‚¬ê°í˜• ë§ˆì»¤, ë¹¨ê°„ í…Œë‘ë¦¬)
        incorrect_mask = class_mask & ~correct_predictions  
        if np.any(incorrect_mask):
            ax.scatter(features_tsne[incorrect_mask, 0], features_tsne[incorrect_mask, 1],
                      c=[color_map[class_id]], s=confidence[incorrect_mask] * 200,
                      alpha=0.7, marker='s', edgecolors='red', linewidths=2,
                      label=f'Class {class_id} (Wrong)')
    
    ax.set_title(f'Prediction Confidence Analysis\n{subject_name} ({model_name}) - Accuracy: {accuracy:.4f}', 
                fontweight='bold', fontsize=12)
    ax.legend(frameon=False)
    ax.set_xticks([])
    ax.set_yticks([])
    sns.despine(ax=ax, left=True, bottom=True)
    
    # ì‹ ë¢°ë„ ë²”ë¡€ ì¶”ê°€
    confidence_legend = [plt.scatter([], [], s=conf*200, c='gray', alpha=0.7, edgecolors='black') 
                        for conf in [0.5, 0.7, 0.9]]
    legend2 = ax.legend(confidence_legend, ['Low Conf (0.5)', 'Med Conf (0.7)', 'High Conf (0.9)'], 
                       loc='upper right', title='Confidence', frameon=False)
    ax.add_artist(ax.legend_)  # í´ë˜ìŠ¤ ë²”ë¡€ ìœ ì§€
    
    plt.tight_layout()
    
    # ì €ì¥
    if save_path:
        base_filename = f"{subject_name}_prediction_confidence_tsne"
        
        # PNG ì €ì¥
        png_filename = f"{base_filename}.png"
        plt.savefig(os.path.join(save_path, png_filename), dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ PNG ì €ì¥: {png_filename}")
        
        # SVG ì €ì¥
        svg_filename = f"{base_filename}.svg"
        plt.savefig(os.path.join(save_path, svg_filename), format='svg', bbox_inches='tight')
        print(f"ğŸ’¾ SVG ì €ì¥: {svg_filename}")
    
    plt.show()


def analyze_misclassification_patterns(data_dict: Dict, save_path: Optional[str] = None):
    """ì˜¤ë¶„ë¥˜ íŒ¨í„´ ìƒì„¸ ë¶„ì„"""
    features = data_dict['features']
    target_labels = data_dict['target_labels']
    predictions = data_dict['predictions']
    correct_predictions = data_dict['correct_predictions']
    subject_name = data_dict['subject_name']
    model_name = data_dict['model_name']
    accuracy = data_dict['accuracy']
    
    print(f"ğŸ¯ {subject_name} ì˜¤ë¶„ë¥˜ íŒ¨í„´ ë¶„ì„ ì‹œì‘")
    
    # ì˜¤ë¶„ë¥˜ ìƒ˜í”Œë“¤ë§Œ ì¶”ì¶œ
    misclassified_mask = ~correct_predictions
    
    if not np.any(misclassified_mask):
        print(f"âœ… {subject_name}: ì˜¤ë¶„ë¥˜ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤ (ì™„ë²½í•œ ì„±ëŠ¥!)")
        return
    
    misclassified_features = features[misclassified_mask]
    misclassified_true = target_labels[misclassified_mask]
    misclassified_pred = predictions[misclassified_mask]
    
    print(f"   ì˜¤ë¶„ë¥˜ ìƒ˜í”Œ ìˆ˜: {len(misclassified_features)} / {len(features)}")
    
    # ì˜¤ë¶„ë¥˜ ìœ í˜•ë³„ ë¶„ì„
    confusion_types = {}
    for true_class in np.unique(target_labels):
        for pred_class in np.unique(predictions):
            if true_class != pred_class:
                mask = (misclassified_true == true_class) & (misclassified_pred == pred_class)
                if np.any(mask):
                    confusion_types[f'{true_class}â†’{pred_class}'] = np.sum(mask)
    
    if not confusion_types:
        print(f"   í˜¼ë™ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    print(f"   ë°œê²¬ëœ í˜¼ë™ íŒ¨í„´: {confusion_types}")
    
    # ì „ì²´ íŠ¹ì§•ê³¼ ì˜¤ë¶„ë¥˜ íŠ¹ì§• í•¨ê»˜ ì‹œê°í™”
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    
    # t-SNE ìˆ˜í–‰
    perplexity_val = min(30, features.shape[0] - 1)
    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity_val,
               max_iter=1000, init='pca', learning_rate='auto')
    features_tsne = tsne.fit_transform(features_scaled)
    
    # ì‹œê°í™”
    sns.set_theme(style="white", context="notebook")
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))
    
    # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ
    unique_labels = np.unique(target_labels)
    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}
    
    # ì¢Œì¸¡: ì „ì²´ ë°ì´í„° (ì •í™•/ë¶€ì •í™• êµ¬ë¶„)
    for class_id in unique_labels:
        class_mask = target_labels == class_id
        
        # ì •í™•í•œ ì˜ˆì¸¡
        correct_mask = class_mask & correct_predictions
        if np.any(correct_mask):
            ax1.scatter(features_tsne[correct_mask, 0], features_tsne[correct_mask, 1],
                       c=[color_map[class_id]], marker='o', s=40, alpha=0.6,
                       label=f'Class {class_id} (Correct)', edgecolors='black', linewidth=0.3)
        
        # í‹€ë¦° ì˜ˆì¸¡ (ê°•ì¡°)
        incorrect_mask = class_mask & ~correct_predictions
        if np.any(incorrect_mask):
            ax1.scatter(features_tsne[incorrect_mask, 0], features_tsne[incorrect_mask, 1],
                       c=[color_map[class_id]], marker='X', s=100, alpha=1.0,
                       label=f'Class {class_id} (Wrong)', edgecolors='red', linewidths=2)
    
    ax1.set_title(f'All Samples with Misclassifications Highlighted\n{subject_name} (Acc: {accuracy:.4f})', 
                 fontweight='bold')
    ax1.legend(frameon=False, fontsize=8)
    ax1.set_xticks([])
    ax1.set_yticks([])
    sns.despine(ax=ax1, left=True, bottom=True)
    
    # ìš°ì¸¡: ì˜¤ë¶„ë¥˜ ìƒ˜í”Œë§Œ (í˜¼ë™ ìœ í˜•ë³„)
    misclassified_tsne = features_tsne[misclassified_mask]
    confusion_colors = plt.cm.Set1(np.linspace(0, 1, len(confusion_types)))
    
    for i, (conf_type, count) in enumerate(confusion_types.items()):
        true_class, pred_class = map(int, conf_type.split('â†’'))
        type_mask = (misclassified_true == true_class) & (misclassified_pred == pred_class)
        
        if np.any(type_mask):
            ax2.scatter(misclassified_tsne[type_mask, 0], misclassified_tsne[type_mask, 1],
                       c=[confusion_colors[i]], s=80, alpha=0.8,
                       label=f'{conf_type} ({count} samples)', 
                       edgecolors='black', linewidth=0.5)
    
    ax2.set_title(f'Misclassification Patterns in Feature Space\n{model_name}', fontweight='bold')
    ax2.legend(frameon=False, fontsize=8)
    ax2.set_xticks([])
    ax2.set_yticks([])
    sns.despine(ax=ax2, left=True, bottom=True)
    
    plt.tight_layout()
    
    # ì €ì¥
    if save_path:
        base_filename = f"{subject_name}_misclassification_analysis"
        
        # PNG ì €ì¥
        png_filename = f"{base_filename}.png"
        plt.savefig(os.path.join(save_path, png_filename), dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ PNG ì €ì¥: {png_filename}")
        
        # SVG ì €ì¥
        svg_filename = f"{base_filename}.svg"
        plt.savefig(os.path.join(save_path, svg_filename), format='svg', bbox_inches='tight')
        print(f"ğŸ’¾ SVG ì €ì¥: {svg_filename}")
    
    plt.show()


def calculate_feature_space_metrics(data_dict: Dict) -> Dict:
    """íŠ¹ì§• ê³µê°„ì—ì„œì˜ ì •ëŸ‰ì  ë©”íŠ¸ë¦­ ê³„ì‚°"""
    features = data_dict['features']
    target_labels = data_dict['target_labels']
    predictions = data_dict['predictions']
    correct_predictions = data_dict['correct_predictions']
    
    metrics = {}
    
    # 1. í´ë˜ìŠ¤ë³„ ì •í™•ë„
    for class_id in np.unique(target_labels):
        class_mask = target_labels == class_id
        if np.sum(class_mask) > 0:
            metrics[f'class_{class_id}_accuracy'] = np.mean(correct_predictions[class_mask])
    
    # 2. íŠ¹ì§• ê³µê°„ì—ì„œì˜ í´ë˜ìŠ¤ ë¶„ë¦¬ë„ (ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´)
    from sklearn.metrics import silhouette_score
    if len(np.unique(target_labels)) > 1:
        try:
            metrics['silhouette_score_true'] = silhouette_score(features, target_labels)
            metrics['silhouette_score_pred'] = silhouette_score(features, predictions)
        except:
            metrics['silhouette_score_true'] = 0.0
            metrics['silhouette_score_pred'] = 0.0
    
    # 3. ì˜¤ë¶„ë¥˜ ì˜ì—­ì˜ íŠ¹ì§• ê³µê°„ ë°€ë„
    misclassified_features = features[~correct_predictions]
    if len(misclassified_features) > 1:
        try:
            from sklearn.metrics.pairwise import euclidean_distances
            distances = euclidean_distances(misclassified_features)
            metrics['misclassification_density'] = np.mean(distances[np.triu_indices_from(distances, k=1)])
        except:
            metrics['misclassification_density'] = 0.0
    
    # 4. ì „ì²´ ì •í™•ë„ ë° ê¸°ë³¸ í†µê³„
    metrics['overall_accuracy'] = np.mean(correct_predictions)
    metrics['num_samples'] = len(features)
    metrics['num_misclassified'] = np.sum(~correct_predictions)
    
    return metrics


def plot_prediction_analysis_tsne(npz_file_path: str, save_path: Optional[str] = None, 
                                 analysis_type: str = 'accuracy'):
    """ì˜ˆì¸¡ ë¶„ì„ ê¸°ë°˜ t-SNE ì‹œê°í™”
    
    Args:
        npz_file_path: NPZ íŒŒì¼ ê²½ë¡œ
        save_path: ì €ì¥ ê²½ë¡œ
        analysis_type: 'accuracy', 'confidence', 'boundary', 'misclassification'
    """
    # ì˜ˆì¸¡ ì •ë³´ë¥¼ í¬í•¨í•œ ë°ì´í„° ë¡œë“œ
    data_dict = load_extracted_features_with_predictions(npz_file_path)
    
    # ì˜ˆì¸¡ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì—ëŸ¬
    if 'predictions' not in data_dict:
        print(f"âŒ {npz_file_path}: ì˜ˆì¸¡ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ í¬í•¨ ëª¨ë“œë¡œ íŠ¹ì§•ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.")
        return False
    
    print(f"ğŸ¯ {data_dict['subject_name']} - {analysis_type} ë¶„ì„ ì‹œì‘")
    
    try:
        if analysis_type == 'accuracy':
            plot_prediction_accuracy_tsne(data_dict, save_path)
        elif analysis_type == 'confidence':
            plot_prediction_confidence_tsne(data_dict, save_path)
        elif analysis_type == 'misclassification':
            analyze_misclassification_patterns(data_dict, save_path)
        else:
            print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ì„ íƒ€ì…: {analysis_type}")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ {analysis_type} ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return False


def prepare_data_for_tsne(input_data: np.ndarray, features: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """t-SNEë¥¼ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬"""
    # ì…ë ¥ ë°ì´í„° í‰ë©´í™” (samples, channels*timepoints)
    input_flat = input_data.reshape(input_data.shape[0], -1)
    
    # í‘œì¤€í™”
    scaler_input = StandardScaler()
    scaler_features = StandardScaler()
    
    input_scaled = scaler_input.fit_transform(input_flat)
    features_scaled = scaler_features.fit_transform(features)
    
    return input_scaled, features_scaled


def plot_input_vs_feature_tsne(data_dict: Dict, save_path: Optional[str] = None):
    """ì…ë ¥ vs íŠ¹ì§• t-SNE ë¹„êµ í”Œë¡¯"""
    input_data = data_dict['input_data']
    features = data_dict['features']
    target_labels = data_dict['target_labels']
    subject_name = data_dict['subject_name']
    model_name = data_dict['model_name']
    
    print(f"ğŸ¯ {subject_name} ({model_name}) t-SNE ë¹„êµ ì‹œì‘")
    print(f"   Input: {input_data.shape}, Features: {features.shape}")
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    input_scaled, features_scaled = prepare_data_for_tsne(input_data, features)
    
    # t-SNE ì‹¤í–‰
    perplexity_val = min(30, input_data.shape[0] - 1)
    
    tsne_input = TSNE(n_components=2, random_state=42, perplexity=perplexity_val, 
                     max_iter=1000, init='pca', learning_rate='auto')
    tsne_features = TSNE(n_components=2, random_state=42, perplexity=perplexity_val,
                        max_iter=1000, init='pca', learning_rate='auto')
    
    input_tsne = tsne_input.fit_transform(input_scaled)
    features_tsne = tsne_features.fit_transform(features_scaled)
    
    # í”Œë¡¯ ìƒì„±
    sns.set_theme(style="white", context="notebook")
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ
    unique_labels = np.unique(target_labels)
    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}
    
    # ì…ë ¥ ë°ì´í„° t-SNE
    ax1 = axes[0]
    for label in unique_labels:
        mask = target_labels == label
        ax1.scatter(input_tsne[mask, 0], input_tsne[mask, 1], 
                   c=[color_map[label]], label=f'Class {label}',
                   alpha=0.7, s=50, edgecolors='black', linewidth=0.3)
    ax1.set_title(f'Input Data t-SNE\n{subject_name}', fontweight='bold')
    ax1.legend(frameon=False)
    ax1.set_xticks([])
    ax1.set_yticks([])
    sns.despine(ax=ax1, left=True, bottom=True)
    
    # íŠ¹ì§• ë°ì´í„° t-SNE  
    ax2 = axes[1]
    for label in unique_labels:
        mask = target_labels == label
        ax2.scatter(features_tsne[mask, 0], features_tsne[mask, 1],
                   c=[color_map[label]], label=f'Class {label}', 
                   alpha=0.7, s=50, edgecolors='black', linewidth=0.3)
    ax2.set_title(f'Extracted Features t-SNE\n{model_name}', fontweight='bold')
    ax2.legend(frameon=False)
    ax2.set_xticks([])
    ax2.set_yticks([])
    sns.despine(ax=ax2, left=True, bottom=True)
    
    plt.tight_layout()
    
    # ì €ì¥ (PNGì™€ SVG ë‘˜ ë‹¤)
    if save_path:
        base_filename = f"{subject_name}_input_vs_features_tsne"
        
        # PNG ì €ì¥
        png_filename = f"{base_filename}.png"
        plt.savefig(os.path.join(save_path, png_filename), dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ PNG ì €ì¥: {png_filename}")
        
        # SVG ì €ì¥
        svg_filename = f"{base_filename}.svg"
        plt.savefig(os.path.join(save_path, svg_filename), format='svg', bbox_inches='tight')
        print(f"ğŸ’¾ SVG ì €ì¥: {svg_filename}")
    
    plt.show()


def plot_all_subjects_combined_tsne(experiment_dir: str, save_path: Optional[str] = None):
    """ì‹¤í—˜ë³„ë¡œ ëª¨ë“  ê°œì²´ë¥¼ í•˜ë‚˜ì˜ ê·¸ë˜í”„ì— í‘œì‹œ"""
    # í•´ë‹¹ ì‹¤í—˜ì˜ NPZ íŒŒì¼ë“¤ ì°¾ê¸° (recursive search)
    npz_pattern = os.path.join(experiment_dir, "extracted_features", "**","*_features.npz")
    npz_files = glob.glob(npz_pattern, recursive=True)
    
    if not npz_files:
        print(f"âŒ NPZ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {experiment_dir}")
        print(f"   ê²€ìƒ‰ íŒ¨í„´: {npz_pattern}")
        return
    
    print(f"ğŸ” ì‹¤í—˜ {os.path.basename(experiment_dir)}: {len(npz_files)}ê°œ ê°œì²´")
    
    # ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘
    all_input_data = []
    all_features_data = []
    all_target_labels = []
    all_subject_labels = []
    
    subject_names = []
    
    for npz_file in npz_files:
        data_dict = load_extracted_features(npz_file)
        subject_name = data_dict['subject_name']
        subject_names.append(subject_name)
        
        # ë°ì´í„° ì¶”ê°€
        all_input_data.append(data_dict['input_data'])
        all_features_data.append(data_dict['features'])
        all_target_labels.append(data_dict['target_labels'])
        all_subject_labels.extend([len(subject_names)-1] * len(data_dict['target_labels']))
    
    # ë°ì´í„° ê²°í•©
    combined_input = np.vstack(all_input_data)
    combined_features = np.vstack(all_features_data)
    combined_target_labels = np.hstack(all_target_labels)
    combined_subject_labels = np.array(all_subject_labels)
    
    print(f"ğŸ“Š ê²°í•©ëœ ë°ì´í„°: Input {combined_input.shape}, Features {combined_features.shape}")
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    input_scaled, features_scaled = prepare_data_for_tsne(combined_input, combined_features)
    
    # t-SNE ì‹¤í–‰
    perplexity_val = min(30, combined_input.shape[0] - 1)
    
    tsne_input = TSNE(n_components=2, random_state=42, perplexity=perplexity_val, 
                     max_iter=1000, init='pca', learning_rate='auto')
    tsne_features = TSNE(n_components=2, random_state=42, perplexity=perplexity_val,
                        max_iter=1000, init='pca', learning_rate='auto')
    
    input_tsne = tsne_input.fit_transform(input_scaled)
    features_tsne = tsne_features.fit_transform(features_scaled)
    
    # í”Œë¡¯ ìƒì„±
    sns.set_theme(style="white", context="notebook")
    fig, axes = plt.subplots(1, 2, figsize=(16, 7))
    
    # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ë° ê°œì²´ë³„ ë§ˆì»¤
    unique_labels = np.unique(combined_target_labels)
    unique_subjects = np.unique(combined_subject_labels)
    
    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}
    
    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'P', '*', 'X', 'h', '+']
    marker_map = {subj: markers[i % len(markers)] for i, subj in enumerate(unique_subjects)}
    
    # ì…ë ¥ ë°ì´í„° t-SNE
    ax1 = axes[0]
    for subj_idx in unique_subjects:
        subj_name = subject_names[subj_idx]
        for label in unique_labels:
            mask = (combined_subject_labels == subj_idx) & (combined_target_labels == label)
            if np.any(mask):
                ax1.scatter(input_tsne[mask, 0], input_tsne[mask, 1], 
                           c=[color_map[label]], marker=marker_map[subj_idx],
                           label=f'{subj_name}_C{label}', alpha=0.7, s=60, 
                           edgecolors='black', linewidth=0.3)
    
    ax1.set_title(f'Input Data t-SNE - All Subjects\n{os.path.basename(experiment_dir)}', fontweight='bold')
    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    ax1.set_xticks([])
    ax1.set_yticks([])
    sns.despine(ax=ax1, left=True, bottom=True)
    
    # íŠ¹ì§• ë°ì´í„° t-SNE  
    ax2 = axes[1]
    for subj_idx in unique_subjects:
        subj_name = subject_names[subj_idx]
        for label in unique_labels:
            mask = (combined_subject_labels == subj_idx) & (combined_target_labels == label)
            if np.any(mask):
                ax2.scatter(features_tsne[mask, 0], features_tsne[mask, 1],
                           c=[color_map[label]], marker=marker_map[subj_idx],
                           label=f'{subj_name}_C{label}', alpha=0.7, s=60, 
                           edgecolors='black', linewidth=0.3)
    
    ax2.set_title(f'Extracted Features t-SNE - All Subjects\nEEGNetLNL', fontweight='bold')
    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    ax2.set_xticks([])
    ax2.set_yticks([])
    sns.despine(ax=ax2, left=True, bottom=True)
    
    plt.tight_layout()
    
    # ì €ì¥ ê²½ë¡œ ì„¤ì •
    if save_path is None:
        save_path = experiment_dir
    
    # ì €ì¥ (PNGì™€ SVG ë‘˜ ë‹¤)
    base_filename = f"{os.path.basename(experiment_dir)}_all_subjects_combined_tsne"
    
    # PNG ì €ì¥
    png_filename = f"{base_filename}.png"
    plt.savefig(os.path.join(save_path, png_filename), dpi=300, bbox_inches='tight')
    print(f"ğŸ’¾ PNG ì €ì¥: {os.path.join(save_path, png_filename)}")
    
    # SVG ì €ì¥
    svg_filename = f"{base_filename}.svg"
    plt.savefig(os.path.join(save_path, svg_filename), format='svg', bbox_inches='tight')
    print(f"ğŸ’¾ SVG ì €ì¥: {os.path.join(save_path, svg_filename)}")
    
    plt.show()


def analyze_all_extracted_features(base_dir: str, save_path: Optional[str] = None):
    """ëª¨ë“  ì¶”ì¶œëœ íŠ¹ì§•ì— ëŒ€í•´ input vs feature t-SNE ë¶„ì„"""
    
    # NPZ íŒŒì¼ ì°¾ê¸°
    npz_pattern = os.path.join(base_dir, "**", "*_features.npz")
    npz_files = glob.glob(npz_pattern, recursive=True)
    
    if not npz_files:
        print(f"âŒ NPZ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {base_dir}")
        return
    
    print(f"ğŸ” ë°œê²¬ëœ NPZ íŒŒì¼: {len(npz_files)}ê°œ")
    
    for npz_file in npz_files:
        print(f"\nğŸ“Š ì²˜ë¦¬ ì¤‘: {os.path.basename(npz_file)}")
        
        try:
            # ë°ì´í„° ë¡œë“œ
            data_dict = load_extracted_features(npz_file)
            
            # t-SNE ë¹„êµ í”Œë¡¯ ìƒì„±
            plot_input_vs_feature_tsne(data_dict, save_path)
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {str(e)}")
            continue
    
    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")


def compare_input_feature_single(npz_file_path: str, save_path: Optional[str] = None):
    """ë‹¨ì¼ NPZ íŒŒì¼ì— ëŒ€í•œ input vs feature ë¹„êµ"""
    print(f"ğŸ¯ ë‹¨ì¼ íŒŒì¼ ë¶„ì„: {os.path.basename(npz_file_path)}")
    
    try:
        data_dict = load_extracted_features(npz_file_path)
        plot_input_vs_feature_tsne(data_dict, save_path)
        return True
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return False


def analyze_experiments_combined(base_dir: str, save_path: Optional[str] = None):
    """ì‹¤í—˜ë³„ë¡œ ëª¨ë“  ê°œì²´ë¥¼ ê²°í•©í•˜ì—¬ ë¶„ì„"""
    
    # ì‹¤í—˜ ë””ë ‰í† ë¦¬ë“¤ ì°¾ê¸° (analyzing_resultê°€ ìˆëŠ” í´ë”ë“¤)
    experiment_dirs = []
    for root, dirs, files in os.walk(base_dir):
        if 'analyzing_result' in dirs:
            analyzing_result_path = os.path.join(root, 'analyzing_result')
            if os.path.exists(os.path.join(analyzing_result_path, 'extracted_features')):
                experiment_dirs.append(analyzing_result_path)
    
    if not experiment_dirs:
        print(f"âŒ ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {base_dir}")
        return
    
    # ê²½ë¡œ ê²€ì¦
    for exp_dir in experiment_dirs:
        if not os.path.exists(exp_dir):
            raise FileNotFoundError(f"ì‹¤í—˜ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {exp_dir}")
        
    print(f"ğŸ” ë°œê²¬ëœ ì‹¤í—˜: {len(experiment_dirs)}ê°œ")
    
    for exp_dir in experiment_dirs:
        experiment_name = os.path.basename(os.path.dirname(exp_dir))
        print(f"\nğŸ“Š ì‹¤í—˜ ì²˜ë¦¬ ì¤‘: {experiment_name}")
        
        try:
            plot_all_subjects_combined_tsne(exp_dir, save_path)
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {str(e)}")
            continue
    
    print(f"\nâœ… ëª¨ë“  ì‹¤í—˜ ë¶„ì„ ì™„ë£Œ!")


def plot_augmentation_comparison_tsne(data_dict: Dict, save_path: Optional[str] = None, plot_type: str = "type1"):
    """ë°ì´í„° ì¦ê°• ë¹„êµ t-SNE í”Œë¡¯
    
    Args:
        data_dict: ì›ë³¸ê³¼ ì¦ê°•ëœ ë°ì´í„°ë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
        save_path: ì €ì¥ ê²½ë¡œ
        plot_type: "type1", "type2", "type3" ì¤‘ í•˜ë‚˜
    """
    original_data = data_dict['original']
    augmented_data = data_dict['augmented']
    
    # Typeë³„ í”Œë¡¯ ì„¤ì •
    if plot_type == "type1":
        # Type 1: ì›ë³¸ ì…ë ¥ + ì¦ê°•ëœ ì…ë ¥ + ì¦ê°•ëœ ì…ë ¥ì˜ íŠ¹ì§• ë²¡í„°
        plot_data = [
            ("Original Input", original_data['input_data'], original_data['target_labels']),
            ("Augmented Input", augmented_data['input_data'], augmented_data['target_labels']),
            ("Augmented Features", augmented_data['features'], augmented_data['target_labels'])
        ]
        title_suffix = "Original vs Augmented Input + Aug Features"
    elif plot_type == "type2":
        # Type 2: ì›ë³¸ ì…ë ¥ + ì›ë³¸ ì…ë ¥ì˜ íŠ¹ì§• ë²¡í„°
        plot_data = [
            ("Original Input", original_data['input_data'], original_data['target_labels']),
            ("Original Features", original_data['features'], original_data['target_labels'])
        ]
        title_suffix = "Original Input vs Features"
    elif plot_type == "type3":
        # Type 3: ì¦ê°•ëœ ì…ë ¥ + ì¦ê°•ëœ ì…ë ¥ì˜ íŠ¹ì§• ë²¡í„°
        plot_data = [
            ("Augmented Input", augmented_data['input_data'], augmented_data['target_labels']),
            ("Augmented Features", augmented_data['features'], augmented_data['target_labels'])
        ]
        title_suffix = "Augmented Input vs Features"
    else:
        raise ValueError(f"Invalid plot_type: {plot_type}")
    
    n_plots = len(plot_data)
    fig, axes = plt.subplots(1, n_plots, figsize=(6*n_plots, 6))
    if n_plots == 1:
        axes = [axes]
    
    sns.set_theme(style="white", context="notebook")
    
    # ê³µí†µ ìƒ‰ìƒ ì„¤ì •
    unique_labels = np.unique(original_data['target_labels'])
    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}
    
    for idx, (name, data, labels) in enumerate(plot_data):
        # ë°ì´í„° ì „ì²˜ë¦¬
        if len(data.shape) > 2:  # ì…ë ¥ ë°ì´í„°ì¸ ê²½ìš°
            data_flat = data.reshape(data.shape[0], -1)
        else:  # íŠ¹ì§• ë°ì´í„°ì¸ ê²½ìš°
            data_flat = data
        
        # í‘œì¤€í™”
        scaler = StandardScaler()
        data_scaled = scaler.fit_transform(data_flat)
        
        # t-SNE
        perplexity_val = min(30, data.shape[0] - 1)
        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity_val, 
                   max_iter=1000, init='pca', learning_rate='auto')
        data_tsne = tsne.fit_transform(data_scaled)
        
        # í”Œë¡¯
        ax = axes[idx]
        for label in unique_labels:
            mask = labels == label
            ax.scatter(data_tsne[mask, 0], data_tsne[mask, 1], 
                      c=[color_map[label]], label=f'Class {label}',
                      alpha=0.7, s=50, edgecolors='black', linewidth=0.3)
        
        ax.set_title(f'{name} t-SNE', fontweight='bold')
        ax.legend(frameon=False)
        ax.set_xticks([])
        ax.set_yticks([])
        sns.despine(ax=ax, left=True, bottom=True)
    
    plt.suptitle(f'{title_suffix}', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    if save_path:
        filename = f"augmentation_comparison_{plot_type}"
        plt.savefig(os.path.join(save_path, f"{filename}.png"), dpi=300, bbox_inches='tight')
        plt.savefig(os.path.join(save_path, f"{filename}.svg"), format='svg', bbox_inches='tight')
        print(f"ğŸ’¾ ì €ì¥: {filename}")
    
    plt.show()


def analyze_augmentation_effects(npz_file_original: str, npz_file_augmented: str, save_path: Optional[str] = None):
    """ë°ì´í„° ì¦ê°• íš¨ê³¼ ì¢…í•© ë¶„ì„"""
    print("ğŸ” ë°ì´í„° ì¦ê°• íš¨ê³¼ ë¶„ì„ ì‹œì‘")
    
    # ë°ì´í„° ë¡œë“œ
    orig_data = load_extracted_features(npz_file_original)
    aug_data = load_extracted_features(npz_file_augmented)
    
    combined_data = {
        'original': orig_data,
        'augmented': aug_data
    }
    
    # 3ê°€ì§€ íƒ€ì… ëª¨ë‘ ìƒì„±
    for plot_type in ["type1", "type2", "type3"]:
        print(f"\nğŸ“Š {plot_type.upper()} ì‹œê°í™” ìƒì„±")
        plot_augmentation_comparison_tsne(combined_data, save_path, plot_type)


def extract_and_visualize_augmentation(analysis_result_path: str, test_config_base_path: str, 
                                     test_data_default_path: str, output_dir: str,
                                     data_augmentation_config_path: str, max_extractions: int = 1):
    """ì¦ê°• ë°ì´í„° ì¶”ì¶œ ë° ì‹œê°í™” í†µí•© í•¨ìˆ˜"""
    from .checkpoint_feature_extractor import CheckpointFeatureRunner, FeatureExtractor
    
    print("ğŸš€ ë°ì´í„° ì¦ê°• ì¶”ì¶œ ë° ì‹œê°í™” ì‹œì‘")
    
    # ì²´í¬í¬ì¸íŠ¸ ì •ë³´ ë¡œë“œ
    import pandas as pd
    df = pd.read_csv(analysis_result_path)
    valid_df = df[df['checkpoint_found'] == True].head(max_extractions)
    
    if len(valid_df) == 0:
        print("âŒ ìœ íš¨í•œ ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    extractor = FeatureExtractor(test_data_default_path)
    
    for _, checkpoint_info in valid_df.iterrows():
        subject_name = checkpoint_info['test_subject_name']
        checkpoint_path = checkpoint_info['checkpoint_path']
        
        print(f"\nğŸ¯ {subject_name} ì²˜ë¦¬ ì¤‘...")
        
        try:
            # ëª¨ë¸ ë¡œë“œ
            from .checkpoint_feature_extractor import EEGNetLNL  # ì ì ˆí•œ ëª¨ë¸ import
            model = extractor.load_model_from_checkpoint(checkpoint_path, "EEGNetLNL")
            
            # ì›ë³¸ ë°ì´í„° ëª¨ë“ˆ
            data_module_orig = extractor.create_data_module(
                f"{test_config_base_path}/{subject_name}.json", 16, None)
            
            # ì¦ê°• ë°ì´í„° ëª¨ë“ˆ  
            da_config = extractor.create_data_augmentation_config(data_augmentation_config_path)
            data_module_aug = extractor.create_data_module(
                f"{test_config_base_path}/{subject_name}.json", 16, da_config)
            
            # íŠ¹ì§• ì¶”ì¶œ
            aug_data = extractor.extract_augmented_features(model, data_module_orig, data_module_aug)
            
            # ì‹œê°í™”
            subject_output_dir = os.path.join(output_dir, subject_name)
            os.makedirs(subject_output_dir, exist_ok=True)
            
            # 3ê°€ì§€ íƒ€ì… ì‹œê°í™”
            for plot_type in ["type1", "type2", "type3"]:
                plot_augmentation_comparison_tsne(aug_data, subject_output_dir, plot_type)
            
        except Exception as e:
            print(f"âŒ {subject_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue


def analyze_augmentation_experiments_combined(base_dir: str, save_path: Optional[str] = None):
    """ì‹¤í—˜ë³„ë¡œ ëª¨ë“  ê°œì²´ì˜ ë°ì´í„° ì¦ê°• ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ë¶„ì„"""
    
    # ì‹¤í—˜ ë””ë ‰í† ë¦¬ë“¤ ì°¾ê¸° (analyzing_resultê°€ ìˆëŠ” í´ë”ë“¤)
    experiment_dirs = []
    for root, dirs, files in os.walk(base_dir):
        if 'analyzing_result' in dirs:
            analyzing_result_path = os.path.join(root, 'analyzing_result')
            augmentation_path = os.path.join(analyzing_result_path, 'augmentation_visualization')
            if os.path.exists(augmentation_path):
                experiment_dirs.append(analyzing_result_path)
    
    if not experiment_dirs:
        print(f"âŒ ë°ì´í„° ì¦ê°• ì‹œê°í™” ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {base_dir}")
        return
    
    print(f"ğŸ” ë°œê²¬ëœ ì‹¤í—˜: {len(experiment_dirs)}ê°œ")
    
    for exp_dir in experiment_dirs:
        experiment_name = os.path.basename(os.path.dirname(exp_dir))
        print(f"\nğŸ“Š ì‹¤í—˜ ì²˜ë¦¬ ì¤‘: {experiment_name}")
        
        try:
            plot_all_subjects_augmentation_combined(exp_dir, save_path)
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {str(e)}")
            continue
    
    print(f"\nâœ… ëª¨ë“  ë°ì´í„° ì¦ê°• ì‹¤í—˜ ë¶„ì„ ì™„ë£Œ!")


def plot_all_subjects_augmentation_combined(analyzing_result_dir: str, save_path: Optional[str] = None):
    """í•œ ì‹¤í—˜ì˜ ëª¨ë“  ê°œì²´ ë°ì´í„° ì¦ê°• ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ì‹œê°í™”"""
    
    augmentation_dir = os.path.join(analyzing_result_dir, 'augmentation_visualization')
    
    if not os.path.exists(augmentation_dir):
        print(f"âŒ ë°ì´í„° ì¦ê°• ì‹œê°í™” í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {augmentation_dir}")
        return
    
    # ê°œì²´ë³„ í´ë” ì°¾ê¸°
    subject_dirs = [d for d in os.listdir(augmentation_dir) 
                   if os.path.isdir(os.path.join(augmentation_dir, d))]
    
    if not subject_dirs:
        print(f"âŒ ê°œì²´ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {augmentation_dir}")
        return
    
    print(f"ğŸ” ë°œê²¬ëœ ê°œì²´: {len(subject_dirs)}ê°œ - {subject_dirs}")
    
    # ê° ê°œì²´ë³„ë¡œ ë°ì´í„° ë¡œë“œ ë° ê²°í•©
    combined_data = {
        'type1': {'original_input': [], 'augmented_input': [], 'augmented_features': [], 'labels': [], 'subjects': []},
        'type2': {'original_input': [], 'original_features': [], 'labels': [], 'subjects': []},
        'type3': {'augmented_input': [], 'augmented_features': [], 'labels': [], 'subjects': []}
    }
    
    subject_loaded = []
    
    for subject_name in subject_dirs:
        subject_path = os.path.join(augmentation_dir, subject_name)
        
        # ê° ê°œì²´ì˜ ë°ì´í„° ë¡œë“œ (NPZ íŒŒì¼ì´ë‚˜ ê¸°íƒ€ ì €ì¥ëœ ë°ì´í„°)
        try:
            # ì‹¤ì œë¡œëŠ” ë°ì´í„° ì¦ê°• ê²°ê³¼ë¥¼ ì–´ë”˜ê°€ì— ì €ì¥í•´ì•¼ í•¨
            # í˜„ì¬ëŠ” ì˜ˆì‹œë¡œ NPZ íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •
            orig_npz_pattern = os.path.join(subject_path, "*_original_features.npz")
            aug_npz_pattern = os.path.join(subject_path, "*_augmented_features.npz")
            
            orig_files = glob.glob(orig_npz_pattern)
            aug_files = glob.glob(aug_npz_pattern)
            
            if not orig_files or not aug_files:
                print(f"âš ï¸ {subject_name}: í•„ìš”í•œ NPZ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                continue
            
            # ë°ì´í„° ë¡œë“œ
            orig_data = np.load(orig_files[0])
            aug_data = np.load(aug_files[0])
            
            # Type 1 ë°ì´í„° ê²°í•©
            combined_data['type1']['original_input'].append(orig_data['input_data'])
            combined_data['type1']['augmented_input'].append(aug_data['input_data'])
            combined_data['type1']['augmented_features'].append(aug_data['features'])
            combined_data['type1']['labels'].append(orig_data['target_labels'])
            combined_data['type1']['subjects'].extend([subject_name] * len(orig_data['target_labels']))
            
            # Type 2 ë°ì´í„° ê²°í•©
            combined_data['type2']['original_input'].append(orig_data['input_data'])
            combined_data['type2']['original_features'].append(orig_data['features'])
            combined_data['type2']['labels'].append(orig_data['target_labels'])
            combined_data['type2']['subjects'].extend([subject_name] * len(orig_data['target_labels']))
            
            # Type 3 ë°ì´í„° ê²°í•©
            combined_data['type3']['augmented_input'].append(aug_data['input_data'])
            combined_data['type3']['augmented_features'].append(aug_data['features'])
            combined_data['type3']['labels'].append(aug_data['target_labels'])
            combined_data['type3']['subjects'].extend([subject_name] * len(aug_data['target_labels']))
            
            subject_loaded.append(subject_name)
            
        except Exception as e:
            print(f"âš ï¸ {subject_name} ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            continue
    
    if not subject_loaded:
        print("âŒ ë¡œë“œëœ ê°œì²´ê°€ ì—†ìŠµë‹ˆë‹¤")
        return
    
    print(f"âœ… ë¡œë“œëœ ê°œì²´: {len(subject_loaded)}ê°œ - {subject_loaded}")
    
    # ê° íƒ€ì…ë³„ë¡œ ì‹œê°í™” ìƒì„±
    experiment_name = os.path.basename(os.path.dirname(analyzing_result_dir))
    
    for plot_type in ['type1', 'type2', 'type3']:
        try:
            plot_combined_augmentation_tsne(combined_data[plot_type], plot_type, 
                                          experiment_name, subject_loaded, 
                                          analyzing_result_dir if save_path is None else save_path)
        except Exception as e:
            print(f"âŒ {plot_type} ì‹œê°í™” ì‹¤íŒ¨: {str(e)}")
            continue


def plot_combined_augmentation_tsne(data_dict: Dict, plot_type: str, experiment_name: str, 
                                   subjects: List[str], save_path: str):
    """ê²°í•©ëœ ë°ì´í„°ë¡œ ì¦ê°• t-SNE ì‹œê°í™”"""
    
    # ë°ì´í„° ê²°í•©
    if plot_type == 'type1':
        # Type 1: ì›ë³¸ ì…ë ¥ + ì¦ê°•ëœ ì…ë ¥ + ì¦ê°•ëœ íŠ¹ì§•
        orig_input = np.vstack(data_dict['original_input'])
        aug_input = np.vstack(data_dict['augmented_input'])
        aug_features = np.vstack(data_dict['augmented_features'])
        labels = np.hstack(data_dict['labels'])
        subjects_list = data_dict['subjects']
        
        plot_data = [
            ("Original Input", orig_input, labels),
            ("Augmented Input", aug_input, labels),
            ("Augmented Features", aug_features, labels)
        ]
        title_suffix = "Original vs Augmented Input + Aug Features"
        
    elif plot_type == 'type2':
        # Type 2: ì›ë³¸ ì…ë ¥ + ì›ë³¸ íŠ¹ì§•
        orig_input = np.vstack(data_dict['original_input'])
        orig_features = np.vstack(data_dict['original_features'])
        labels = np.hstack(data_dict['labels'])
        subjects_list = data_dict['subjects']
        
        plot_data = [
            ("Original Input", orig_input, labels),
            ("Original Features", orig_features, labels)
        ]
        title_suffix = "Original Input vs Features"
        
    elif plot_type == 'type3':
        # Type 3: ì¦ê°•ëœ ì…ë ¥ + ì¦ê°•ëœ íŠ¹ì§•
        aug_input = np.vstack(data_dict['augmented_input'])
        aug_features = np.vstack(data_dict['augmented_features'])
        labels = np.hstack(data_dict['labels'])
        subjects_list = data_dict['subjects']
        
        plot_data = [
            ("Augmented Input", aug_input, labels),
            ("Augmented Features", aug_features, labels)
        ]
        title_suffix = "Augmented Input vs Features"
    
    # ì‹œê°í™” ìƒì„±
    n_plots = len(plot_data)
    fig, axes = plt.subplots(1, n_plots, figsize=(8*n_plots, 8))
    if n_plots == 1:
        axes = [axes]
    
    sns.set_theme(style="white", context="notebook")
    
    # ê³µí†µ ìƒ‰ìƒ ì„¤ì • (í´ë˜ìŠ¤ë³„)
    unique_labels = np.unique(labels)
    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
    color_map = {label: colors[i] for i, label in enumerate(unique_labels)}
    
    # ê°œì²´ë³„ ë§ˆì»¤ ì„¤ì •
    unique_subjects = list(set(subjects_list))
    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'h'][: len(unique_subjects)]
    marker_map = {subj: markers[i] for i, subj in enumerate(unique_subjects)}
    
    for idx, (name, data, plot_labels) in enumerate(plot_data):
        # ë°ì´í„° ì „ì²˜ë¦¬
        if len(data.shape) > 2:  # ì…ë ¥ ë°ì´í„°ì¸ ê²½ìš°
            data_flat = data.reshape(data.shape[0], -1)
        else:  # íŠ¹ì§• ë°ì´í„°ì¸ ê²½ìš°
            data_flat = data
        
        # í‘œì¤€í™”
        scaler = StandardScaler()
        data_scaled = scaler.fit_transform(data_flat)
        
        # t-SNE
        perplexity_val = min(30, data.shape[0] - 1)
        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity_val, 
                   max_iter=1000, init='pca', learning_rate='auto')
        data_tsne = tsne.fit_transform(data_scaled)
        
        # í”Œë¡¯
        ax = axes[idx]
        
        # í´ë˜ìŠ¤ë³„, ê°œì²´ë³„ë¡œ í”Œë¡¯
        for label in unique_labels:
            for subject in unique_subjects:
                # í•´ë‹¹ í´ë˜ìŠ¤ì™€ ê°œì²´ì— ì†í•˜ëŠ” í¬ì¸íŠ¸ë“¤ ì°¾ê¸°
                label_mask = plot_labels == label
                subject_mask = np.array([s == subject for s in subjects_list])
                mask = label_mask & subject_mask
                
                if np.sum(mask) > 0:
                    ax.scatter(data_tsne[mask, 0], data_tsne[mask, 1],
                             c=[color_map[label]], marker=marker_map[subject],
                             label=f'{subject}-Class{label}', alpha=0.7, s=60,
                             edgecolors='black', linewidth=0.3)
        
        ax.set_title(f'{name} t-SNE\n({len(unique_subjects)} subjects combined)', 
                    fontweight='bold', fontsize=12)
        ax.legend(frameon=False, fontsize=8, ncol=2)
        ax.set_xticks([])
        ax.set_yticks([])
        sns.despine(ax=ax, left=True, bottom=True)
    
    plt.suptitle(f'{experiment_name} - {title_suffix}\nCombined Analysis ({len(unique_subjects)} subjects)', 
                fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    # ì €ì¥
    filename = f"augmentation_combined_{plot_type}_{experiment_name}"
    plt.savefig(os.path.join(save_path, f"{filename}.png"), dpi=300, bbox_inches='tight')
    plt.savefig(os.path.join(save_path, f"{filename}.svg"), format='svg', bbox_inches='tight')
    print(f"ğŸ’¾ ì €ì¥: {filename}")
    
    plt.show()


    plt.show()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    base_dir = "/home/jsw/Fairness/tmp/Fairness_for_generalization/results_trans/results_trans/results_subject_60"
    save_dir = "/home/jsw/Fairness/tmp/Fairness_for_generalization/visualization_results"
    
    analyze_all_extracted_features(base_dir, save_dir)
